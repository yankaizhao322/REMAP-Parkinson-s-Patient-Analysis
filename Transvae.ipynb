{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32aba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "加载并预处理所有 STS 关键点数据...\n",
      "训练序列数量: 323, 验证序列数量: 81\n",
      "Fitting scaler on entire dataset for normalization...\n",
      "Scaler fitted.\n",
      "初始化模型...\n",
      "开始训练模型...\n",
      "Epoch 1 Complete | Avg Train Loss: 2385.8835 | Avg Train Recon Loss: 2383.4447 | Avg Train KL Loss: 2438.8123\n",
      "Epoch 1 Validation | Avg Val Loss: 741.7767 | Avg Val Recon Loss: 736.3333 | Avg Val KL Loss: 5443.3860\n",
      "✔ 最佳模型已保存，验证损失: 741.7767\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 2 Complete | Avg Train Loss: 873.7699 | Avg Train Recon Loss: 867.4068 | Avg Train KL Loss: 6363.0289\n",
      "Epoch 2 Validation | Avg Val Loss: 614.1824 | Avg Val Recon Loss: 606.2773 | Avg Val KL Loss: 7905.0868\n",
      "✔ 最佳模型已保存，验证损失: 614.1824\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 3 Complete | Avg Train Loss: 777.8743 | Avg Train Recon Loss: 769.9543 | Avg Train KL Loss: 7920.0485\n",
      "Epoch 3 Validation | Avg Val Loss: 555.7573 | Avg Val Recon Loss: 547.1304 | Avg Val KL Loss: 8626.9402\n",
      "✔ 最佳模型已保存，验证损失: 555.7573\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 4 Complete | Avg Train Loss: 738.9619 | Avg Train Recon Loss: 730.6813 | Avg Train KL Loss: 8280.5298\n",
      "Epoch 4 Validation | Avg Val Loss: 538.5217 | Avg Val Recon Loss: 529.8987 | Avg Val KL Loss: 8622.9728\n",
      "✔ 最佳模型已保存，验证损失: 538.5217\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 5 Complete | Avg Train Loss: 717.6306 | Avg Train Recon Loss: 709.4722 | Avg Train KL Loss: 8158.4107\n",
      "Epoch 5 Validation | Avg Val Loss: 529.3116 | Avg Val Recon Loss: 520.8718 | Avg Val KL Loss: 8439.8152\n",
      "✔ 最佳模型已保存，验证损失: 529.3116\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 6 Complete | Avg Train Loss: 691.0335 | Avg Train Recon Loss: 683.1244 | Avg Train KL Loss: 7909.1713\n",
      "Epoch 6 Validation | Avg Val Loss: 505.4645 | Avg Val Recon Loss: 497.4044 | Avg Val KL Loss: 8060.1339\n",
      "✔ 最佳模型已保存，验证损失: 505.4645\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 7 Complete | Avg Train Loss: 659.6990 | Avg Train Recon Loss: 652.2073 | Avg Train KL Loss: 7491.6637\n",
      "Epoch 7 Validation | Avg Val Loss: 481.3205 | Avg Val Recon Loss: 473.7238 | Avg Val KL Loss: 7596.7546\n",
      "✔ 最佳模型已保存，验证损失: 481.3205\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 8 Complete | Avg Train Loss: 628.5465 | Avg Train Recon Loss: 621.5670 | Avg Train KL Loss: 6979.4822\n",
      "Epoch 8 Validation | Avg Val Loss: 460.6088 | Avg Val Recon Loss: 453.5583 | Avg Val KL Loss: 7050.4917\n",
      "✔ 最佳模型已保存，验证损失: 460.6088\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 9 Complete | Avg Train Loss: 598.0787 | Avg Train Recon Loss: 591.6443 | Avg Train KL Loss: 6434.4896\n",
      "Epoch 9 Validation | Avg Val Loss: 433.8115 | Avg Val Recon Loss: 427.3511 | Avg Val KL Loss: 6460.3804\n",
      "✔ 最佳模型已保存，验证损失: 433.8115\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 10 Complete | Avg Train Loss: 566.4458 | Avg Train Recon Loss: 560.5548 | Avg Train KL Loss: 5891.0358\n",
      "Epoch 10 Validation | Avg Val Loss: 411.9303 | Avg Val Recon Loss: 405.9926 | Avg Val KL Loss: 5937.6989\n",
      "✔ 最佳模型已保存，验证损失: 411.9303\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 11 Complete | Avg Train Loss: 540.7503 | Avg Train Recon Loss: 535.4070 | Avg Train KL Loss: 5343.3515\n",
      "Epoch 11 Validation | Avg Val Loss: 386.8909 | Avg Val Recon Loss: 381.4986 | Avg Val KL Loss: 5392.3241\n",
      "✔ 最佳模型已保存，验证损失: 386.8909\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 12 Complete | Avg Train Loss: 517.4419 | Avg Train Recon Loss: 512.5999 | Avg Train KL Loss: 4841.9787\n",
      "Epoch 12 Validation | Avg Val Loss: 374.9465 | Avg Val Recon Loss: 370.0318 | Avg Val KL Loss: 4914.7014\n",
      "✔ 最佳模型已保存，验证损失: 374.9465\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 13 Complete | Avg Train Loss: 503.2732 | Avg Train Recon Loss: 498.8341 | Avg Train KL Loss: 4439.0466\n",
      "Epoch 13 Validation | Avg Val Loss: 372.9092 | Avg Val Recon Loss: 368.3441 | Avg Val KL Loss: 4565.1013\n",
      "✔ 最佳模型已保存，验证损失: 372.9092\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 14 Complete | Avg Train Loss: 491.3533 | Avg Train Recon Loss: 487.2076 | Avg Train KL Loss: 4145.7331\n",
      "Epoch 14 Validation | Avg Val Loss: 359.1367 | Avg Val Recon Loss: 354.7900 | Avg Val KL Loss: 4346.7427\n",
      "✔ 最佳模型已保存，验证损失: 359.1367\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 15 Complete | Avg Train Loss: 478.5615 | Avg Train Recon Loss: 474.6436 | Avg Train KL Loss: 3917.8654\n",
      "Epoch 15 Validation | Avg Val Loss: 353.5286 | Avg Val Recon Loss: 349.4514 | Avg Val KL Loss: 4077.1952\n",
      "✔ 最佳模型已保存，验证损失: 353.5286\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 16 Complete | Avg Train Loss: 468.8364 | Avg Train Recon Loss: 465.1882 | Avg Train KL Loss: 3648.1076\n",
      "Epoch 16 Validation | Avg Val Loss: 351.1541 | Avg Val Recon Loss: 347.3588 | Avg Val KL Loss: 3795.2725\n",
      "✔ 最佳模型已保存，验证损失: 351.1541\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 17 Complete | Avg Train Loss: 461.7631 | Avg Train Recon Loss: 458.3491 | Avg Train KL Loss: 3414.0264\n",
      "Epoch 17 Validation | Avg Val Loss: 345.1305 | Avg Val Recon Loss: 341.5404 | Avg Val KL Loss: 3589.9998\n",
      "✔ 最佳模型已保存，验证损失: 345.1305\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 18 Complete | Avg Train Loss: 454.1512 | Avg Train Recon Loss: 450.9097 | Avg Train KL Loss: 3241.5505\n",
      "Epoch 18 Validation | Avg Val Loss: 340.9564 | Avg Val Recon Loss: 337.5455 | Avg Val KL Loss: 3410.8962\n",
      "✔ 最佳模型已保存，验证损失: 340.9564\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 19 Complete | Avg Train Loss: 446.7570 | Avg Train Recon Loss: 443.6820 | Avg Train KL Loss: 3074.9937\n",
      "Epoch 19 Validation | Avg Val Loss: 344.6292 | Avg Val Recon Loss: 341.4054 | Avg Val KL Loss: 3223.8128\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 20 Complete | Avg Train Loss: 442.5278 | Avg Train Recon Loss: 439.5598 | Avg Train KL Loss: 2967.9615\n",
      "Epoch 20 Validation | Avg Val Loss: 345.2967 | Avg Val Recon Loss: 342.1248 | Avg Val KL Loss: 3171.9165\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 21 Complete | Avg Train Loss: 436.5712 | Avg Train Recon Loss: 433.6717 | Avg Train KL Loss: 2899.5461\n",
      "Epoch 21 Validation | Avg Val Loss: 339.1997 | Avg Val Recon Loss: 336.1225 | Avg Val KL Loss: 3077.2804\n",
      "✔ 最佳模型已保存，验证损失: 339.1997\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 22 Complete | Avg Train Loss: 429.9276 | Avg Train Recon Loss: 427.1505 | Avg Train KL Loss: 2777.0871\n",
      "Epoch 22 Validation | Avg Val Loss: 338.3875 | Avg Val Recon Loss: 335.4466 | Avg Val KL Loss: 2940.8709\n",
      "✔ 最佳模型已保存，验证损失: 338.3875\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 23 Complete | Avg Train Loss: 425.8864 | Avg Train Recon Loss: 423.1771 | Avg Train KL Loss: 2709.2705\n",
      "Epoch 23 Validation | Avg Val Loss: 337.4125 | Avg Val Recon Loss: 334.5132 | Avg Val KL Loss: 2899.3100\n",
      "✔ 最佳模型已保存，验证损失: 337.4125\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 24 Complete | Avg Train Loss: 419.2778 | Avg Train Recon Loss: 416.6560 | Avg Train KL Loss: 2621.7896\n",
      "Epoch 24 Validation | Avg Val Loss: 327.9759 | Avg Val Recon Loss: 325.2155 | Avg Val KL Loss: 2760.4135\n",
      "✔ 最佳模型已保存，验证损失: 327.9759\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 25 Complete | Avg Train Loss: 411.9777 | Avg Train Recon Loss: 409.4914 | Avg Train KL Loss: 2486.3389\n",
      "Epoch 25 Validation | Avg Val Loss: 328.6999 | Avg Val Recon Loss: 326.0644 | Avg Val KL Loss: 2635.5123\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 26 Complete | Avg Train Loss: 406.3343 | Avg Train Recon Loss: 403.9526 | Avg Train KL Loss: 2381.7381\n",
      "Epoch 26 Validation | Avg Val Loss: 331.3009 | Avg Val Recon Loss: 328.7834 | Avg Val KL Loss: 2517.4532\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 27 Complete | Avg Train Loss: 402.7582 | Avg Train Recon Loss: 400.4599 | Avg Train KL Loss: 2298.3374\n",
      "Epoch 27 Validation | Avg Val Loss: 315.8506 | Avg Val Recon Loss: 313.3824 | Avg Val KL Loss: 2468.1953\n",
      "✔ 最佳模型已保存，验证损失: 315.8506\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 28 Complete | Avg Train Loss: 390.4169 | Avg Train Recon Loss: 388.2606 | Avg Train KL Loss: 2156.2931\n",
      "Epoch 28 Validation | Avg Val Loss: 314.4772 | Avg Val Recon Loss: 312.0935 | Avg Val KL Loss: 2383.6970\n",
      "✔ 最佳模型已保存，验证损失: 314.4772\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 29 Complete | Avg Train Loss: 379.8807 | Avg Train Recon Loss: 377.8256 | Avg Train KL Loss: 2055.1676\n",
      "Epoch 29 Validation | Avg Val Loss: 318.7015 | Avg Val Recon Loss: 316.4742 | Avg Val KL Loss: 2227.2546\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 30 Complete | Avg Train Loss: 379.0993 | Avg Train Recon Loss: 376.8041 | Avg Train KL Loss: 2295.2189\n",
      "Epoch 30 Validation | Avg Val Loss: 304.9805 | Avg Val Recon Loss: 302.4785 | Avg Val KL Loss: 2501.9867\n",
      "✔ 最佳模型已保存，验证损失: 304.9805\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 31 Complete | Avg Train Loss: 373.2436 | Avg Train Recon Loss: 370.9098 | Avg Train KL Loss: 2333.7518\n",
      "Epoch 31 Validation | Avg Val Loss: 360.6910 | Avg Val Recon Loss: 357.9269 | Avg Val KL Loss: 2764.0417\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 32 Complete | Avg Train Loss: 372.7639 | Avg Train Recon Loss: 370.1005 | Avg Train KL Loss: 2663.3824\n",
      "Epoch 32 Validation | Avg Val Loss: 285.3379 | Avg Val Recon Loss: 282.5739 | Avg Val KL Loss: 2763.9923\n",
      "✔ 最佳模型已保存，验证损失: 285.3379\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 33 Complete | Avg Train Loss: 340.9023 | Avg Train Recon Loss: 338.4324 | Avg Train KL Loss: 2469.8609\n",
      "Epoch 33 Validation | Avg Val Loss: 293.2394 | Avg Val Recon Loss: 290.4093 | Avg Val KL Loss: 2830.1093\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 34 Complete | Avg Train Loss: 337.7465 | Avg Train Recon Loss: 335.1752 | Avg Train KL Loss: 2571.3193\n",
      "Epoch 34 Validation | Avg Val Loss: 271.6403 | Avg Val Recon Loss: 268.9520 | Avg Val KL Loss: 2688.2782\n",
      "✔ 最佳模型已保存，验证损失: 271.6403\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 35 Complete | Avg Train Loss: 324.3362 | Avg Train Recon Loss: 321.7942 | Avg Train KL Loss: 2542.0505\n",
      "Epoch 35 Validation | Avg Val Loss: 275.3232 | Avg Val Recon Loss: 272.4815 | Avg Val KL Loss: 2841.6945\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 36 Complete | Avg Train Loss: 321.9706 | Avg Train Recon Loss: 319.3676 | Avg Train KL Loss: 2603.0215\n",
      "Epoch 36 Validation | Avg Val Loss: 263.6940 | Avg Val Recon Loss: 260.9460 | Avg Val KL Loss: 2747.9744\n",
      "✔ 最佳模型已保存，验证损失: 263.6940\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 37 Complete | Avg Train Loss: 314.0548 | Avg Train Recon Loss: 311.4408 | Avg Train KL Loss: 2614.0494\n",
      "Epoch 37 Validation | Avg Val Loss: 263.9354 | Avg Val Recon Loss: 261.0679 | Avg Val KL Loss: 2867.5032\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 38 Complete | Avg Train Loss: 310.4548 | Avg Train Recon Loss: 307.7944 | Avg Train KL Loss: 2660.4408\n",
      "Epoch 38 Validation | Avg Val Loss: 263.1008 | Avg Val Recon Loss: 260.3036 | Avg Val KL Loss: 2797.2052\n",
      "✔ 最佳模型已保存，验证损失: 263.1008\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 39 Complete | Avg Train Loss: 311.4113 | Avg Train Recon Loss: 308.7099 | Avg Train KL Loss: 2701.3571\n",
      "Epoch 39 Validation | Avg Val Loss: 268.8024 | Avg Val Recon Loss: 265.8076 | Avg Val KL Loss: 2994.8283\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 40 Complete | Avg Train Loss: 309.5896 | Avg Train Recon Loss: 306.8930 | Avg Train KL Loss: 2696.5521\n",
      "Epoch 40 Validation | Avg Val Loss: 256.1944 | Avg Val Recon Loss: 253.2780 | Avg Val KL Loss: 2916.3515\n",
      "✔ 最佳模型已保存，验证损失: 256.1944\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 41 Complete | Avg Train Loss: 302.9028 | Avg Train Recon Loss: 300.1867 | Avg Train KL Loss: 2716.0581\n",
      "Epoch 41 Validation | Avg Val Loss: 256.2319 | Avg Val Recon Loss: 253.2841 | Avg Val KL Loss: 2947.7558\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 42 Complete | Avg Train Loss: 299.0959 | Avg Train Recon Loss: 296.3838 | Avg Train KL Loss: 2712.1712\n",
      "Epoch 42 Validation | Avg Val Loss: 261.1408 | Avg Val Recon Loss: 258.2636 | Avg Val KL Loss: 2877.1904\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 43 Complete | Avg Train Loss: 299.9179 | Avg Train Recon Loss: 297.2094 | Avg Train KL Loss: 2708.4751\n",
      "Epoch 43 Validation | Avg Val Loss: 250.3123 | Avg Val Recon Loss: 247.3684 | Avg Val KL Loss: 2943.9616\n",
      "✔ 最佳模型已保存，验证损失: 250.3123\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 44 Complete | Avg Train Loss: 292.4825 | Avg Train Recon Loss: 289.7437 | Avg Train KL Loss: 2738.8400\n",
      "Epoch 44 Validation | Avg Val Loss: 249.3398 | Avg Val Recon Loss: 246.3054 | Avg Val KL Loss: 3034.4071\n",
      "✔ 最佳模型已保存，验证损失: 249.3398\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 45 Complete | Avg Train Loss: 290.7583 | Avg Train Recon Loss: 288.0592 | Avg Train KL Loss: 2699.1691\n",
      "Epoch 45 Validation | Avg Val Loss: 247.2634 | Avg Val Recon Loss: 244.3358 | Avg Val KL Loss: 2927.5979\n",
      "✔ 最佳模型已保存，验证损失: 247.2634\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 46 Complete | Avg Train Loss: 285.3656 | Avg Train Recon Loss: 282.6282 | Avg Train KL Loss: 2737.4072\n",
      "Epoch 46 Validation | Avg Val Loss: 244.2375 | Avg Val Recon Loss: 241.2970 | Avg Val KL Loss: 2940.5551\n",
      "✔ 最佳模型已保存，验证损失: 244.2375\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 47 Complete | Avg Train Loss: 282.3531 | Avg Train Recon Loss: 279.6423 | Avg Train KL Loss: 2710.8267\n",
      "Epoch 47 Validation | Avg Val Loss: 241.8525 | Avg Val Recon Loss: 238.9432 | Avg Val KL Loss: 2909.2733\n",
      "✔ 最佳模型已保存，验证损失: 241.8525\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 48 Complete | Avg Train Loss: 281.0354 | Avg Train Recon Loss: 278.3239 | Avg Train KL Loss: 2711.5295\n",
      "Epoch 48 Validation | Avg Val Loss: 242.5523 | Avg Val Recon Loss: 239.6582 | Avg Val KL Loss: 2894.0867\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 49 Complete | Avg Train Loss: 278.1435 | Avg Train Recon Loss: 275.4347 | Avg Train KL Loss: 2708.8054\n",
      "Epoch 49 Validation | Avg Val Loss: 249.8328 | Avg Val Recon Loss: 246.8512 | Avg Val KL Loss: 2981.6247\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 50 Complete | Avg Train Loss: 276.0553 | Avg Train Recon Loss: 273.3529 | Avg Train KL Loss: 2702.3476\n",
      "Epoch 50 Validation | Avg Val Loss: 231.7208 | Avg Val Recon Loss: 228.7629 | Avg Val KL Loss: 2957.8880\n",
      "✔ 最佳模型已保存，验证损失: 231.7208\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 51 Complete | Avg Train Loss: 269.7432 | Avg Train Recon Loss: 267.0648 | Avg Train KL Loss: 2678.3239\n",
      "Epoch 51 Validation | Avg Val Loss: 228.6394 | Avg Val Recon Loss: 225.7803 | Avg Val KL Loss: 2859.0676\n",
      "✔ 最佳模型已保存，验证损失: 228.6394\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 52 Complete | Avg Train Loss: 267.1874 | Avg Train Recon Loss: 264.5254 | Avg Train KL Loss: 2661.9943\n",
      "Epoch 52 Validation | Avg Val Loss: 235.1848 | Avg Val Recon Loss: 232.4256 | Avg Val KL Loss: 2759.1639\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 53 Complete | Avg Train Loss: 265.1469 | Avg Train Recon Loss: 262.5652 | Avg Train KL Loss: 2581.7626\n",
      "Epoch 53 Validation | Avg Val Loss: 226.1795 | Avg Val Recon Loss: 223.3022 | Avg Val KL Loss: 2877.3185\n",
      "✔ 最佳模型已保存，验证损失: 226.1795\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 54 Complete | Avg Train Loss: 265.0454 | Avg Train Recon Loss: 262.4428 | Avg Train KL Loss: 2602.5707\n",
      "Epoch 54 Validation | Avg Val Loss: 253.2021 | Avg Val Recon Loss: 250.3930 | Avg Val KL Loss: 2809.1153\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 55 Complete | Avg Train Loss: 276.2900 | Avg Train Recon Loss: 273.7056 | Avg Train KL Loss: 2584.4399\n",
      "Epoch 55 Validation | Avg Val Loss: 251.4534 | Avg Val Recon Loss: 248.4947 | Avg Val KL Loss: 2958.6692\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 56 Complete | Avg Train Loss: 269.0359 | Avg Train Recon Loss: 266.3965 | Avg Train KL Loss: 2639.3960\n",
      "Epoch 56 Validation | Avg Val Loss: 232.7886 | Avg Val Recon Loss: 230.0248 | Avg Val KL Loss: 2763.8209\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 57 Complete | Avg Train Loss: 259.5754 | Avg Train Recon Loss: 257.0603 | Avg Train KL Loss: 2515.0760\n",
      "Epoch 57 Validation | Avg Val Loss: 225.6923 | Avg Val Recon Loss: 222.9107 | Avg Val KL Loss: 2781.6300\n",
      "✔ 最佳模型已保存，验证损失: 225.6923\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 58 Complete | Avg Train Loss: 255.7295 | Avg Train Recon Loss: 253.2150 | Avg Train KL Loss: 2514.4981\n",
      "Epoch 58 Validation | Avg Val Loss: 239.2786 | Avg Val Recon Loss: 236.5478 | Avg Val KL Loss: 2730.8384\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 59 Complete | Avg Train Loss: 257.5041 | Avg Train Recon Loss: 255.0030 | Avg Train KL Loss: 2501.0725\n",
      "Epoch 59 Validation | Avg Val Loss: 264.8065 | Avg Val Recon Loss: 262.1428 | Avg Val KL Loss: 2663.7359\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 60 Complete | Avg Train Loss: 262.6106 | Avg Train Recon Loss: 260.2185 | Avg Train KL Loss: 2392.0924\n",
      "Epoch 60 Validation | Avg Val Loss: 222.1528 | Avg Val Recon Loss: 219.5282 | Avg Val KL Loss: 2624.5923\n",
      "✔ 最佳模型已保存，验证损失: 222.1528\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 61 Complete | Avg Train Loss: 250.3641 | Avg Train Recon Loss: 247.9309 | Avg Train KL Loss: 2433.1102\n",
      "Epoch 61 Validation | Avg Val Loss: 233.5622 | Avg Val Recon Loss: 230.9282 | Avg Val KL Loss: 2634.0542\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 62 Complete | Avg Train Loss: 257.5817 | Avg Train Recon Loss: 255.1576 | Avg Train KL Loss: 2424.1265\n",
      "Epoch 62 Validation | Avg Val Loss: 225.9014 | Avg Val Recon Loss: 223.2716 | Avg Val KL Loss: 2629.7899\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 63 Complete | Avg Train Loss: 247.3320 | Avg Train Recon Loss: 244.8825 | Avg Train KL Loss: 2449.4794\n",
      "Epoch 63 Validation | Avg Val Loss: 218.4779 | Avg Val Recon Loss: 215.8958 | Avg Val KL Loss: 2582.1244\n",
      "✔ 最佳模型已保存，验证损失: 218.4779\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 64 Complete | Avg Train Loss: 246.0234 | Avg Train Recon Loss: 243.6307 | Avg Train KL Loss: 2392.7552\n",
      "Epoch 64 Validation | Avg Val Loss: 217.8583 | Avg Val Recon Loss: 215.2585 | Avg Val KL Loss: 2599.8145\n",
      "✔ 最佳模型已保存，验证损失: 217.8583\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 65 Complete | Avg Train Loss: 251.0728 | Avg Train Recon Loss: 248.6599 | Avg Train KL Loss: 2412.8634\n",
      "Epoch 65 Validation | Avg Val Loss: 267.4475 | Avg Val Recon Loss: 264.8751 | Avg Val KL Loss: 2572.4035\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 66 Complete | Avg Train Loss: 262.7298 | Avg Train Recon Loss: 260.3376 | Avg Train KL Loss: 2392.2096\n",
      "Epoch 66 Validation | Avg Val Loss: 213.8452 | Avg Val Recon Loss: 211.3160 | Avg Val KL Loss: 2529.2729\n",
      "✔ 最佳模型已保存，验证损失: 213.8452\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 67 Complete | Avg Train Loss: 240.6600 | Avg Train Recon Loss: 238.3090 | Avg Train KL Loss: 2351.0471\n",
      "Epoch 67 Validation | Avg Val Loss: 209.8430 | Avg Val Recon Loss: 207.2695 | Avg Val KL Loss: 2573.5864\n",
      "✔ 最佳模型已保存，验证损失: 209.8430\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 68 Complete | Avg Train Loss: 236.4008 | Avg Train Recon Loss: 234.1102 | Avg Train KL Loss: 2290.5204\n",
      "Epoch 68 Validation | Avg Val Loss: 207.2822 | Avg Val Recon Loss: 204.8697 | Avg Val KL Loss: 2412.5046\n",
      "✔ 最佳模型已保存，验证损失: 207.2822\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 69 Complete | Avg Train Loss: 232.4234 | Avg Train Recon Loss: 230.1955 | Avg Train KL Loss: 2227.8981\n",
      "Epoch 69 Validation | Avg Val Loss: 202.0934 | Avg Val Recon Loss: 199.6656 | Avg Val KL Loss: 2427.8681\n",
      "✔ 最佳模型已保存，验证损失: 202.0934\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 70 Complete | Avg Train Loss: 228.1623 | Avg Train Recon Loss: 225.9224 | Avg Train KL Loss: 2239.8498\n",
      "Epoch 70 Validation | Avg Val Loss: 199.4136 | Avg Val Recon Loss: 196.9886 | Avg Val KL Loss: 2425.0322\n",
      "✔ 最佳模型已保存，验证损失: 199.4136\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 71 Complete | Avg Train Loss: 227.0944 | Avg Train Recon Loss: 224.8383 | Avg Train KL Loss: 2256.0436\n",
      "Epoch 71 Validation | Avg Val Loss: 200.7710 | Avg Val Recon Loss: 198.3746 | Avg Val KL Loss: 2396.4195\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 72 Complete | Avg Train Loss: 225.7931 | Avg Train Recon Loss: 223.5469 | Avg Train KL Loss: 2246.1669\n",
      "Epoch 72 Validation | Avg Val Loss: 207.9788 | Avg Val Recon Loss: 205.5685 | Avg Val KL Loss: 2410.2921\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 73 Complete | Avg Train Loss: 226.5939 | Avg Train Recon Loss: 224.3096 | Avg Train KL Loss: 2284.2934\n",
      "Epoch 73 Validation | Avg Val Loss: 204.3491 | Avg Val Recon Loss: 201.8663 | Avg Val KL Loss: 2482.7681\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 74 Complete | Avg Train Loss: 223.6458 | Avg Train Recon Loss: 221.3400 | Avg Train KL Loss: 2305.8317\n",
      "Epoch 74 Validation | Avg Val Loss: 198.9383 | Avg Val Recon Loss: 196.4860 | Avg Val KL Loss: 2452.3348\n",
      "✔ 最佳模型已保存，验证损失: 198.9383\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 75 Complete | Avg Train Loss: 221.4520 | Avg Train Recon Loss: 219.1856 | Avg Train KL Loss: 2266.3771\n",
      "Epoch 75 Validation | Avg Val Loss: 198.9470 | Avg Val Recon Loss: 196.5810 | Avg Val KL Loss: 2366.0163\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 76 Complete | Avg Train Loss: 218.5539 | Avg Train Recon Loss: 216.3518 | Avg Train KL Loss: 2202.0239\n",
      "Epoch 76 Validation | Avg Val Loss: 194.1489 | Avg Val Recon Loss: 191.7407 | Avg Val KL Loss: 2408.1611\n",
      "✔ 最佳模型已保存，验证损失: 194.1489\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 77 Complete | Avg Train Loss: 216.1515 | Avg Train Recon Loss: 213.9762 | Avg Train KL Loss: 2175.2391\n",
      "Epoch 77 Validation | Avg Val Loss: 201.0517 | Avg Val Recon Loss: 198.6723 | Avg Val KL Loss: 2379.4488\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 78 Complete | Avg Train Loss: 218.3761 | Avg Train Recon Loss: 216.1854 | Avg Train KL Loss: 2190.6892\n",
      "Epoch 78 Validation | Avg Val Loss: 193.1553 | Avg Val Recon Loss: 190.7080 | Avg Val KL Loss: 2447.3068\n",
      "✔ 最佳模型已保存，验证损失: 193.1553\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 79 Complete | Avg Train Loss: 213.5878 | Avg Train Recon Loss: 211.3692 | Avg Train KL Loss: 2218.5966\n",
      "Epoch 79 Validation | Avg Val Loss: 186.8707 | Avg Val Recon Loss: 184.4930 | Avg Val KL Loss: 2377.7329\n",
      "✔ 最佳模型已保存，验证损失: 186.8707\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 80 Complete | Avg Train Loss: 210.6699 | Avg Train Recon Loss: 208.4792 | Avg Train KL Loss: 2190.7029\n",
      "Epoch 80 Validation | Avg Val Loss: 186.2497 | Avg Val Recon Loss: 183.9623 | Avg Val KL Loss: 2287.3631\n",
      "✔ 最佳模型已保存，验证损失: 186.2497\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 81 Complete | Avg Train Loss: 208.1300 | Avg Train Recon Loss: 205.9629 | Avg Train KL Loss: 2167.0965\n",
      "Epoch 81 Validation | Avg Val Loss: 188.7674 | Avg Val Recon Loss: 186.4238 | Avg Val KL Loss: 2343.5322\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 82 Complete | Avg Train Loss: 207.1839 | Avg Train Recon Loss: 205.0425 | Avg Train KL Loss: 2141.3991\n",
      "Epoch 82 Validation | Avg Val Loss: 184.4367 | Avg Val Recon Loss: 182.1195 | Avg Val KL Loss: 2317.2289\n",
      "✔ 最佳模型已保存，验证损失: 184.4367\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 83 Complete | Avg Train Loss: 206.3660 | Avg Train Recon Loss: 204.1955 | Avg Train KL Loss: 2170.5454\n",
      "Epoch 83 Validation | Avg Val Loss: 182.1876 | Avg Val Recon Loss: 179.8672 | Avg Val KL Loss: 2320.4343\n",
      "✔ 最佳模型已保存，验证损失: 182.1876\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 84 Complete | Avg Train Loss: 204.5612 | Avg Train Recon Loss: 202.4070 | Avg Train KL Loss: 2154.2170\n",
      "Epoch 84 Validation | Avg Val Loss: 196.4569 | Avg Val Recon Loss: 194.0863 | Avg Val KL Loss: 2370.5759\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 85 Complete | Avg Train Loss: 215.6884 | Avg Train Recon Loss: 213.5248 | Avg Train KL Loss: 2163.5448\n",
      "Epoch 85 Validation | Avg Val Loss: 219.0399 | Avg Val Recon Loss: 216.5260 | Avg Val KL Loss: 2513.9391\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 86 Complete | Avg Train Loss: 226.9419 | Avg Train Recon Loss: 224.6354 | Avg Train KL Loss: 2306.5070\n",
      "Epoch 86 Validation | Avg Val Loss: 218.5762 | Avg Val Recon Loss: 216.1128 | Avg Val KL Loss: 2463.3443\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 87 Complete | Avg Train Loss: 220.5441 | Avg Train Recon Loss: 218.2558 | Avg Train KL Loss: 2288.2493\n",
      "Epoch 87 Validation | Avg Val Loss: 220.6347 | Avg Val Recon Loss: 218.1778 | Avg Val KL Loss: 2456.8391\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 88 Complete | Avg Train Loss: 217.0185 | Avg Train Recon Loss: 214.8619 | Avg Train KL Loss: 2156.5628\n",
      "Epoch 88 Validation | Avg Val Loss: 195.0764 | Avg Val Recon Loss: 192.7531 | Avg Val KL Loss: 2323.3333\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 89 Complete | Avg Train Loss: 206.5220 | Avg Train Recon Loss: 204.3068 | Avg Train KL Loss: 2215.1605\n",
      "Epoch 89 Validation | Avg Val Loss: 186.6465 | Avg Val Recon Loss: 184.2836 | Avg Val KL Loss: 2362.9144\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 90 Complete | Avg Train Loss: 198.8161 | Avg Train Recon Loss: 196.6311 | Avg Train KL Loss: 2184.9452\n",
      "Epoch 90 Validation | Avg Val Loss: 176.3264 | Avg Val Recon Loss: 174.0363 | Avg Val KL Loss: 2290.1084\n",
      "✔ 最佳模型已保存，验证损失: 176.3264\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 91 Complete | Avg Train Loss: 197.0600 | Avg Train Recon Loss: 194.9703 | Avg Train KL Loss: 2089.6797\n",
      "Epoch 91 Validation | Avg Val Loss: 181.1264 | Avg Val Recon Loss: 178.8613 | Avg Val KL Loss: 2265.0630\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 92 Complete | Avg Train Loss: 196.8031 | Avg Train Recon Loss: 194.7125 | Avg Train KL Loss: 2090.5441\n",
      "Epoch 92 Validation | Avg Val Loss: 184.3185 | Avg Val Recon Loss: 182.0491 | Avg Val KL Loss: 2269.4481\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 93 Complete | Avg Train Loss: 194.5346 | Avg Train Recon Loss: 192.4689 | Avg Train KL Loss: 2065.7893\n",
      "Epoch 93 Validation | Avg Val Loss: 172.8230 | Avg Val Recon Loss: 170.5899 | Avg Val KL Loss: 2233.0975\n",
      "✔ 最佳模型已保存，验证损失: 172.8230\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 94 Complete | Avg Train Loss: 190.3475 | Avg Train Recon Loss: 188.2768 | Avg Train KL Loss: 2070.7171\n",
      "Epoch 94 Validation | Avg Val Loss: 171.4343 | Avg Val Recon Loss: 169.1772 | Avg Val KL Loss: 2257.0642\n",
      "✔ 最佳模型已保存，验证损失: 171.4343\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 95 Complete | Avg Train Loss: 188.6395 | Avg Train Recon Loss: 186.5517 | Avg Train KL Loss: 2087.8287\n",
      "Epoch 95 Validation | Avg Val Loss: 175.3791 | Avg Val Recon Loss: 173.1447 | Avg Val KL Loss: 2234.4235\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 96 Complete | Avg Train Loss: 188.3881 | Avg Train Recon Loss: 186.3408 | Avg Train KL Loss: 2047.2873\n",
      "Epoch 96 Validation | Avg Val Loss: 169.2618 | Avg Val Recon Loss: 167.0147 | Avg Val KL Loss: 2247.0131\n",
      "✔ 最佳模型已保存，验证损失: 169.2618\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 97 Complete | Avg Train Loss: 185.1362 | Avg Train Recon Loss: 183.0786 | Avg Train KL Loss: 2057.5654\n",
      "Epoch 97 Validation | Avg Val Loss: 170.1891 | Avg Val Recon Loss: 167.9882 | Avg Val KL Loss: 2200.8434\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 98 Complete | Avg Train Loss: 184.8662 | Avg Train Recon Loss: 182.8495 | Avg Train KL Loss: 2016.6638\n",
      "Epoch 98 Validation | Avg Val Loss: 165.3486 | Avg Val Recon Loss: 163.1708 | Avg Val KL Loss: 2177.8343\n",
      "✔ 最佳模型已保存，验证损失: 165.3486\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 99 Complete | Avg Train Loss: 182.1567 | Avg Train Recon Loss: 180.1510 | Avg Train KL Loss: 2005.7061\n",
      "Epoch 99 Validation | Avg Val Loss: 166.1467 | Avg Val Recon Loss: 163.9598 | Avg Val KL Loss: 2186.9493\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 100 Complete | Avg Train Loss: 184.6740 | Avg Train Recon Loss: 182.6305 | Avg Train KL Loss: 2043.4446\n",
      "Epoch 100 Validation | Avg Val Loss: 168.1288 | Avg Val Recon Loss: 166.0051 | Avg Val KL Loss: 2123.7395\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 101 Complete | Avg Train Loss: 181.8099 | Avg Train Recon Loss: 179.8141 | Avg Train KL Loss: 1995.7803\n",
      "Epoch 101 Validation | Avg Val Loss: 167.7587 | Avg Val Recon Loss: 165.5486 | Avg Val KL Loss: 2210.0209\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 102 Complete | Avg Train Loss: 180.9517 | Avg Train Recon Loss: 178.9478 | Avg Train KL Loss: 2003.8646\n",
      "Epoch 102 Validation | Avg Val Loss: 164.0321 | Avg Val Recon Loss: 161.9156 | Avg Val KL Loss: 2116.5779\n",
      "✔ 最佳模型已保存，验证损失: 164.0321\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 103 Complete | Avg Train Loss: 177.8816 | Avg Train Recon Loss: 175.9251 | Avg Train KL Loss: 1956.5709\n",
      "Epoch 103 Validation | Avg Val Loss: 168.4661 | Avg Val Recon Loss: 166.3458 | Avg Val KL Loss: 2120.3148\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 104 Complete | Avg Train Loss: 180.3796 | Avg Train Recon Loss: 178.4158 | Avg Train KL Loss: 1963.7780\n",
      "Epoch 104 Validation | Avg Val Loss: 173.9368 | Avg Val Recon Loss: 171.7945 | Avg Val KL Loss: 2142.2965\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 105 Complete | Avg Train Loss: 182.9615 | Avg Train Recon Loss: 180.9706 | Avg Train KL Loss: 1990.8740\n",
      "Epoch 105 Validation | Avg Val Loss: 163.4984 | Avg Val Recon Loss: 161.3444 | Avg Val KL Loss: 2154.0081\n",
      "✔ 最佳模型已保存，验证损失: 163.4984\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 106 Complete | Avg Train Loss: 178.9044 | Avg Train Recon Loss: 176.9551 | Avg Train KL Loss: 1949.3220\n",
      "Epoch 106 Validation | Avg Val Loss: 162.4097 | Avg Val Recon Loss: 160.2570 | Avg Val KL Loss: 2152.7476\n",
      "✔ 最佳模型已保存，验证损失: 162.4097\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 107 Complete | Avg Train Loss: 175.6145 | Avg Train Recon Loss: 173.6372 | Avg Train KL Loss: 1977.2882\n",
      "Epoch 107 Validation | Avg Val Loss: 162.9444 | Avg Val Recon Loss: 160.7675 | Avg Val KL Loss: 2176.8877\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 108 Complete | Avg Train Loss: 179.9652 | Avg Train Recon Loss: 177.9984 | Avg Train KL Loss: 1966.7738\n",
      "Epoch 108 Validation | Avg Val Loss: 173.6731 | Avg Val Recon Loss: 171.5119 | Avg Val KL Loss: 2161.1943\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 109 Complete | Avg Train Loss: 178.0039 | Avg Train Recon Loss: 175.9859 | Avg Train KL Loss: 2018.0198\n",
      "Epoch 109 Validation | Avg Val Loss: 169.5253 | Avg Val Recon Loss: 167.3559 | Avg Val KL Loss: 2169.3343\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 110 Complete | Avg Train Loss: 175.7038 | Avg Train Recon Loss: 173.6878 | Avg Train KL Loss: 2015.9070\n",
      "Epoch 110 Validation | Avg Val Loss: 158.1590 | Avg Val Recon Loss: 155.9584 | Avg Val KL Loss: 2200.5757\n",
      "✔ 最佳模型已保存，验证损失: 158.1590\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 111 Complete | Avg Train Loss: 171.8848 | Avg Train Recon Loss: 169.8422 | Avg Train KL Loss: 2042.5565\n",
      "Epoch 111 Validation | Avg Val Loss: 155.3580 | Avg Val Recon Loss: 153.1367 | Avg Val KL Loss: 2221.3708\n",
      "✔ 最佳模型已保存，验证损失: 155.3580\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 112 Complete | Avg Train Loss: 169.6459 | Avg Train Recon Loss: 167.6248 | Avg Train KL Loss: 2021.1728\n",
      "Epoch 112 Validation | Avg Val Loss: 154.4366 | Avg Val Recon Loss: 152.2755 | Avg Val KL Loss: 2161.1707\n",
      "✔ 最佳模型已保存，验证损失: 154.4366\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 113 Complete | Avg Train Loss: 167.6057 | Avg Train Recon Loss: 165.6198 | Avg Train KL Loss: 1985.9976\n",
      "Epoch 113 Validation | Avg Val Loss: 166.7102 | Avg Val Recon Loss: 164.5801 | Avg Val KL Loss: 2130.0988\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 114 Complete | Avg Train Loss: 172.1111 | Avg Train Recon Loss: 170.1587 | Avg Train KL Loss: 1952.3264\n",
      "Epoch 114 Validation | Avg Val Loss: 169.8223 | Avg Val Recon Loss: 167.7053 | Avg Val KL Loss: 2116.9837\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 115 Complete | Avg Train Loss: 170.4461 | Avg Train Recon Loss: 168.5027 | Avg Train KL Loss: 1943.4280\n",
      "Epoch 115 Validation | Avg Val Loss: 156.5062 | Avg Val Recon Loss: 154.3809 | Avg Val KL Loss: 2125.3515\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 116 Complete | Avg Train Loss: 167.4763 | Avg Train Recon Loss: 165.5045 | Avg Train KL Loss: 1971.7522\n",
      "Epoch 116 Validation | Avg Val Loss: 152.1852 | Avg Val Recon Loss: 150.0936 | Avg Val KL Loss: 2091.5421\n",
      "✔ 最佳模型已保存，验证损失: 152.1852\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 117 Complete | Avg Train Loss: 165.3196 | Avg Train Recon Loss: 163.3742 | Avg Train KL Loss: 1945.3566\n",
      "Epoch 117 Validation | Avg Val Loss: 153.8632 | Avg Val Recon Loss: 151.7613 | Avg Val KL Loss: 2101.9564\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 118 Complete | Avg Train Loss: 164.7128 | Avg Train Recon Loss: 162.7902 | Avg Train KL Loss: 1922.5675\n",
      "Epoch 118 Validation | Avg Val Loss: 162.3953 | Avg Val Recon Loss: 160.3062 | Avg Val KL Loss: 2089.0545\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 119 Complete | Avg Train Loss: 168.5633 | Avg Train Recon Loss: 166.6235 | Avg Train KL Loss: 1939.8027\n",
      "Epoch 119 Validation | Avg Val Loss: 156.8473 | Avg Val Recon Loss: 154.7487 | Avg Val KL Loss: 2098.5748\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 120 Complete | Avg Train Loss: 163.6950 | Avg Train Recon Loss: 161.7392 | Avg Train KL Loss: 1955.8331\n",
      "Epoch 120 Validation | Avg Val Loss: 156.9461 | Avg Val Recon Loss: 154.8062 | Avg Val KL Loss: 2139.8520\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 121 Complete | Avg Train Loss: 163.3236 | Avg Train Recon Loss: 161.3622 | Avg Train KL Loss: 1961.4032\n",
      "Epoch 121 Validation | Avg Val Loss: 146.9213 | Avg Val Recon Loss: 144.8207 | Avg Val KL Loss: 2100.6330\n",
      "✔ 最佳模型已保存，验证损失: 146.9213\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 122 Complete | Avg Train Loss: 160.2034 | Avg Train Recon Loss: 158.3045 | Avg Train KL Loss: 1898.8677\n",
      "Epoch 122 Validation | Avg Val Loss: 145.9318 | Avg Val Recon Loss: 143.8468 | Avg Val KL Loss: 2084.9972\n",
      "✔ 最佳模型已保存，验证损失: 145.9318\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 123 Complete | Avg Train Loss: 157.7423 | Avg Train Recon Loss: 155.8505 | Avg Train KL Loss: 1891.7593\n",
      "Epoch 123 Validation | Avg Val Loss: 151.6776 | Avg Val Recon Loss: 149.6202 | Avg Val KL Loss: 2057.4273\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 124 Complete | Avg Train Loss: 159.2093 | Avg Train Recon Loss: 157.3225 | Avg Train KL Loss: 1886.8009\n",
      "Epoch 124 Validation | Avg Val Loss: 145.7867 | Avg Val Recon Loss: 143.7569 | Avg Val KL Loss: 2029.7717\n",
      "✔ 最佳模型已保存，验证损失: 145.7867\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 125 Complete | Avg Train Loss: 157.8469 | Avg Train Recon Loss: 155.9885 | Avg Train KL Loss: 1858.4127\n",
      "Epoch 125 Validation | Avg Val Loss: 154.2164 | Avg Val Recon Loss: 152.2129 | Avg Val KL Loss: 2003.5294\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 126 Complete | Avg Train Loss: 158.8156 | Avg Train Recon Loss: 156.9263 | Avg Train KL Loss: 1889.3011\n",
      "Epoch 126 Validation | Avg Val Loss: 151.4199 | Avg Val Recon Loss: 149.3856 | Avg Val KL Loss: 2034.3093\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 127 Complete | Avg Train Loss: 158.6608 | Avg Train Recon Loss: 156.7611 | Avg Train KL Loss: 1899.7054\n",
      "Epoch 127 Validation | Avg Val Loss: 153.0633 | Avg Val Recon Loss: 150.9667 | Avg Val KL Loss: 2096.6335\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 128 Complete | Avg Train Loss: 157.6991 | Avg Train Recon Loss: 155.7908 | Avg Train KL Loss: 1908.2338\n",
      "Epoch 128 Validation | Avg Val Loss: 141.2486 | Avg Val Recon Loss: 139.1621 | Avg Val KL Loss: 2086.4629\n",
      "✔ 最佳模型已保存，验证损失: 141.2486\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 129 Complete | Avg Train Loss: 153.3132 | Avg Train Recon Loss: 151.3879 | Avg Train KL Loss: 1925.2346\n",
      "Epoch 129 Validation | Avg Val Loss: 142.6758 | Avg Val Recon Loss: 140.6212 | Avg Val KL Loss: 2054.6550\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 130 Complete | Avg Train Loss: 153.6631 | Avg Train Recon Loss: 151.7585 | Avg Train KL Loss: 1904.5856\n",
      "Epoch 130 Validation | Avg Val Loss: 141.0498 | Avg Val Recon Loss: 138.9345 | Avg Val KL Loss: 2115.3238\n",
      "✔ 最佳模型已保存，验证损失: 141.0498\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 131 Complete | Avg Train Loss: 151.9618 | Avg Train Recon Loss: 150.0754 | Avg Train KL Loss: 1886.3897\n",
      "Epoch 131 Validation | Avg Val Loss: 140.5405 | Avg Val Recon Loss: 138.5639 | Avg Val KL Loss: 1976.5344\n",
      "✔ 最佳模型已保存，验证损失: 140.5405\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 132 Complete | Avg Train Loss: 151.8408 | Avg Train Recon Loss: 149.9840 | Avg Train KL Loss: 1856.7331\n",
      "Epoch 132 Validation | Avg Val Loss: 144.7247 | Avg Val Recon Loss: 142.6715 | Avg Val KL Loss: 2053.2242\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 133 Complete | Avg Train Loss: 154.4736 | Avg Train Recon Loss: 152.6122 | Avg Train KL Loss: 1861.4210\n",
      "Epoch 133 Validation | Avg Val Loss: 153.4801 | Avg Val Recon Loss: 151.4277 | Avg Val KL Loss: 2052.3147\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 134 Complete | Avg Train Loss: 155.7927 | Avg Train Recon Loss: 153.8884 | Avg Train KL Loss: 1904.2807\n",
      "Epoch 134 Validation | Avg Val Loss: 143.2997 | Avg Val Recon Loss: 141.2069 | Avg Val KL Loss: 2092.7560\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 135 Complete | Avg Train Loss: 156.2186 | Avg Train Recon Loss: 154.3069 | Avg Train KL Loss: 1911.7401\n",
      "Epoch 135 Validation | Avg Val Loss: 143.5160 | Avg Val Recon Loss: 141.4557 | Avg Val KL Loss: 2060.3194\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 136 Complete | Avg Train Loss: 153.6551 | Avg Train Recon Loss: 151.7426 | Avg Train KL Loss: 1912.5215\n",
      "Epoch 136 Validation | Avg Val Loss: 142.5810 | Avg Val Recon Loss: 140.5043 | Avg Val KL Loss: 2076.7173\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 137 Complete | Avg Train Loss: 150.2899 | Avg Train Recon Loss: 148.3945 | Avg Train KL Loss: 1895.4151\n",
      "Epoch 137 Validation | Avg Val Loss: 136.2328 | Avg Val Recon Loss: 134.1403 | Avg Val KL Loss: 2092.4877\n",
      "✔ 最佳模型已保存，验证损失: 136.2328\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 138 Complete | Avg Train Loss: 147.8532 | Avg Train Recon Loss: 145.9551 | Avg Train KL Loss: 1898.1331\n",
      "Epoch 138 Validation | Avg Val Loss: 139.0922 | Avg Val Recon Loss: 137.0472 | Avg Val KL Loss: 2044.9956\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 139 Complete | Avg Train Loss: 147.6946 | Avg Train Recon Loss: 145.8228 | Avg Train KL Loss: 1871.8154\n",
      "Epoch 139 Validation | Avg Val Loss: 141.2405 | Avg Val Recon Loss: 139.2423 | Avg Val KL Loss: 1998.2059\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 140 Complete | Avg Train Loss: 147.9044 | Avg Train Recon Loss: 146.0569 | Avg Train KL Loss: 1847.5673\n",
      "Epoch 140 Validation | Avg Val Loss: 134.7877 | Avg Val Recon Loss: 132.7482 | Avg Val KL Loss: 2039.4438\n",
      "✔ 最佳模型已保存，验证损失: 134.7877\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 141 Complete | Avg Train Loss: 147.0181 | Avg Train Recon Loss: 145.1594 | Avg Train KL Loss: 1858.7333\n",
      "Epoch 141 Validation | Avg Val Loss: 143.4731 | Avg Val Recon Loss: 141.5184 | Avg Val KL Loss: 1954.6266\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 142 Complete | Avg Train Loss: 147.8454 | Avg Train Recon Loss: 146.0193 | Avg Train KL Loss: 1826.1370\n",
      "Epoch 142 Validation | Avg Val Loss: 144.9591 | Avg Val Recon Loss: 142.9453 | Avg Val KL Loss: 2013.7884\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 143 Complete | Avg Train Loss: 148.5870 | Avg Train Recon Loss: 146.7944 | Avg Train KL Loss: 1792.6140\n",
      "Epoch 143 Validation | Avg Val Loss: 139.1028 | Avg Val Recon Loss: 137.1214 | Avg Val KL Loss: 1981.3253\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 144 Complete | Avg Train Loss: 145.8581 | Avg Train Recon Loss: 144.0525 | Avg Train KL Loss: 1805.6594\n",
      "Epoch 144 Validation | Avg Val Loss: 135.4934 | Avg Val Recon Loss: 133.5187 | Avg Val KL Loss: 1974.7213\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 145 Complete | Avg Train Loss: 144.4208 | Avg Train Recon Loss: 142.6183 | Avg Train KL Loss: 1802.5551\n",
      "Epoch 145 Validation | Avg Val Loss: 128.9628 | Avg Val Recon Loss: 127.0198 | Avg Val KL Loss: 1942.9916\n",
      "✔ 最佳模型已保存，验证损失: 128.9628\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 146 Complete | Avg Train Loss: 141.7389 | Avg Train Recon Loss: 139.9585 | Avg Train KL Loss: 1780.4331\n",
      "Epoch 146 Validation | Avg Val Loss: 136.5267 | Avg Val Recon Loss: 134.5493 | Avg Val KL Loss: 1977.4446\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 147 Complete | Avg Train Loss: 143.3020 | Avg Train Recon Loss: 141.5371 | Avg Train KL Loss: 1764.8386\n",
      "Epoch 147 Validation | Avg Val Loss: 135.2614 | Avg Val Recon Loss: 133.3479 | Avg Val KL Loss: 1913.5554\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 148 Complete | Avg Train Loss: 140.7237 | Avg Train Recon Loss: 138.9928 | Avg Train KL Loss: 1730.8952\n",
      "Epoch 148 Validation | Avg Val Loss: 132.4099 | Avg Val Recon Loss: 130.4852 | Avg Val KL Loss: 1924.7034\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 149 Complete | Avg Train Loss: 141.1238 | Avg Train Recon Loss: 139.3580 | Avg Train KL Loss: 1765.7950\n",
      "Epoch 149 Validation | Avg Val Loss: 131.6003 | Avg Val Recon Loss: 129.6787 | Avg Val KL Loss: 1921.6310\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 150 Complete | Avg Train Loss: 141.1411 | Avg Train Recon Loss: 139.4021 | Avg Train KL Loss: 1738.9583\n",
      "Epoch 150 Validation | Avg Val Loss: 131.2264 | Avg Val Recon Loss: 129.3484 | Avg Val KL Loss: 1878.0257\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 151 Complete | Avg Train Loss: 138.9572 | Avg Train Recon Loss: 137.2164 | Avg Train KL Loss: 1740.7648\n",
      "Epoch 151 Validation | Avg Val Loss: 130.1734 | Avg Val Recon Loss: 128.2460 | Avg Val KL Loss: 1927.3295\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 152 Complete | Avg Train Loss: 138.5085 | Avg Train Recon Loss: 136.7672 | Avg Train KL Loss: 1741.3310\n",
      "Epoch 152 Validation | Avg Val Loss: 129.3036 | Avg Val Recon Loss: 127.4502 | Avg Val KL Loss: 1853.3506\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 153 Complete | Avg Train Loss: 139.3009 | Avg Train Recon Loss: 137.5930 | Avg Train KL Loss: 1707.9573\n",
      "Epoch 153 Validation | Avg Val Loss: 129.0686 | Avg Val Recon Loss: 127.2004 | Avg Val KL Loss: 1868.1529\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 154 Complete | Avg Train Loss: 137.8110 | Avg Train Recon Loss: 136.0795 | Avg Train KL Loss: 1731.4949\n",
      "Epoch 154 Validation | Avg Val Loss: 124.8441 | Avg Val Recon Loss: 122.9800 | Avg Val KL Loss: 1864.1565\n",
      "✔ 最佳模型已保存，验证损失: 124.8441\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 155 Complete | Avg Train Loss: 137.1686 | Avg Train Recon Loss: 135.4764 | Avg Train KL Loss: 1692.2815\n",
      "Epoch 155 Validation | Avg Val Loss: 130.6798 | Avg Val Recon Loss: 128.8139 | Avg Val KL Loss: 1865.8722\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 156 Complete | Avg Train Loss: 137.8395 | Avg Train Recon Loss: 136.1457 | Avg Train KL Loss: 1693.8346\n",
      "Epoch 156 Validation | Avg Val Loss: 136.5006 | Avg Val Recon Loss: 134.7346 | Avg Val KL Loss: 1766.0021\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 157 Complete | Avg Train Loss: 139.1412 | Avg Train Recon Loss: 137.4233 | Avg Train KL Loss: 1717.9579\n",
      "Epoch 157 Validation | Avg Val Loss: 127.1841 | Avg Val Recon Loss: 125.2802 | Avg Val KL Loss: 1903.8739\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 158 Complete | Avg Train Loss: 136.1033 | Avg Train Recon Loss: 134.3532 | Avg Train KL Loss: 1750.1782\n",
      "Epoch 158 Validation | Avg Val Loss: 127.2631 | Avg Val Recon Loss: 125.3232 | Avg Val KL Loss: 1939.8393\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 159 Complete | Avg Train Loss: 137.4957 | Avg Train Recon Loss: 135.7191 | Avg Train KL Loss: 1776.5314\n",
      "Epoch 159 Validation | Avg Val Loss: 135.4075 | Avg Val Recon Loss: 133.4920 | Avg Val KL Loss: 1915.4918\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 160 Complete | Avg Train Loss: 141.6071 | Avg Train Recon Loss: 139.8322 | Avg Train KL Loss: 1774.9804\n",
      "Epoch 160 Validation | Avg Val Loss: 183.1090 | Avg Val Recon Loss: 181.2330 | Avg Val KL Loss: 1876.0622\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 161 Complete | Avg Train Loss: 152.9539 | Avg Train Recon Loss: 151.3018 | Avg Train KL Loss: 1652.0396\n",
      "Epoch 161 Validation | Avg Val Loss: 143.8127 | Avg Val Recon Loss: 142.1791 | Avg Val KL Loss: 1633.5850\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 162 Complete | Avg Train Loss: 147.0988 | Avg Train Recon Loss: 145.4519 | Avg Train KL Loss: 1646.9103\n",
      "Epoch 162 Validation | Avg Val Loss: 160.1100 | Avg Val Recon Loss: 158.2234 | Avg Val KL Loss: 1886.6033\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 163 Complete | Avg Train Loss: 149.0777 | Avg Train Recon Loss: 147.3081 | Avg Train KL Loss: 1769.6071\n",
      "Epoch 163 Validation | Avg Val Loss: 167.0852 | Avg Val Recon Loss: 165.2316 | Avg Val KL Loss: 1853.5988\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 164 Complete | Avg Train Loss: 164.4044 | Avg Train Recon Loss: 162.6345 | Avg Train KL Loss: 1769.9370\n",
      "Epoch 164 Validation | Avg Val Loss: 161.8068 | Avg Val Recon Loss: 159.9189 | Avg Val KL Loss: 1887.9499\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 165 Complete | Avg Train Loss: 150.0376 | Avg Train Recon Loss: 148.2236 | Avg Train KL Loss: 1813.9126\n",
      "Epoch 165 Validation | Avg Val Loss: 137.1674 | Avg Val Recon Loss: 135.1415 | Avg Val KL Loss: 2025.8079\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 166 Complete | Avg Train Loss: 140.2968 | Avg Train Recon Loss: 138.4440 | Avg Train KL Loss: 1852.7311\n",
      "Epoch 166 Validation | Avg Val Loss: 127.9305 | Avg Val Recon Loss: 125.9575 | Avg Val KL Loss: 1972.9431\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 167 Complete | Avg Train Loss: 134.8833 | Avg Train Recon Loss: 133.0592 | Avg Train KL Loss: 1824.1214\n",
      "Epoch 167 Validation | Avg Val Loss: 124.1238 | Avg Val Recon Loss: 122.1951 | Avg Val KL Loss: 1928.7000\n",
      "✔ 最佳模型已保存，验证损失: 124.1238\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 168 Complete | Avg Train Loss: 131.6587 | Avg Train Recon Loss: 129.8924 | Avg Train KL Loss: 1766.3533\n",
      "Epoch 168 Validation | Avg Val Loss: 121.3516 | Avg Val Recon Loss: 119.4904 | Avg Val KL Loss: 1861.1937\n",
      "✔ 最佳模型已保存，验证损失: 121.3516\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 169 Complete | Avg Train Loss: 130.3578 | Avg Train Recon Loss: 128.6589 | Avg Train KL Loss: 1698.9383\n",
      "Epoch 169 Validation | Avg Val Loss: 121.2141 | Avg Val Recon Loss: 119.4050 | Avg Val KL Loss: 1809.1527\n",
      "✔ 最佳模型已保存，验证损失: 121.2141\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 170 Complete | Avg Train Loss: 130.4252 | Avg Train Recon Loss: 128.7836 | Avg Train KL Loss: 1641.5637\n",
      "Epoch 170 Validation | Avg Val Loss: 132.2237 | Avg Val Recon Loss: 130.4612 | Avg Val KL Loss: 1762.5890\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 171 Complete | Avg Train Loss: 132.6327 | Avg Train Recon Loss: 131.0299 | Avg Train KL Loss: 1602.7363\n",
      "Epoch 171 Validation | Avg Val Loss: 120.6380 | Avg Val Recon Loss: 118.8760 | Avg Val KL Loss: 1761.9645\n",
      "✔ 最佳模型已保存，验证损失: 120.6380\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 172 Complete | Avg Train Loss: 130.1151 | Avg Train Recon Loss: 128.5109 | Avg Train KL Loss: 1604.1732\n",
      "Epoch 172 Validation | Avg Val Loss: 120.4474 | Avg Val Recon Loss: 118.7081 | Avg Val KL Loss: 1739.2485\n",
      "✔ 最佳模型已保存，验证损失: 120.4474\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 173 Complete | Avg Train Loss: 129.1225 | Avg Train Recon Loss: 127.5081 | Avg Train KL Loss: 1614.4622\n",
      "Epoch 173 Validation | Avg Val Loss: 123.0621 | Avg Val Recon Loss: 121.2630 | Avg Val KL Loss: 1799.0986\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 174 Complete | Avg Train Loss: 129.2484 | Avg Train Recon Loss: 127.6207 | Avg Train KL Loss: 1627.7537\n",
      "Epoch 174 Validation | Avg Val Loss: 121.9291 | Avg Val Recon Loss: 120.2157 | Avg Val KL Loss: 1713.4107\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 175 Complete | Avg Train Loss: 128.2647 | Avg Train Recon Loss: 126.6571 | Avg Train KL Loss: 1607.5942\n",
      "Epoch 175 Validation | Avg Val Loss: 123.3331 | Avg Val Recon Loss: 121.5978 | Avg Val KL Loss: 1735.3077\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 176 Complete | Avg Train Loss: 129.1259 | Avg Train Recon Loss: 127.5231 | Avg Train KL Loss: 1602.7938\n",
      "Epoch 176 Validation | Avg Val Loss: 123.5171 | Avg Val Recon Loss: 121.7917 | Avg Val KL Loss: 1725.3342\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 177 Complete | Avg Train Loss: 130.6728 | Avg Train Recon Loss: 129.0873 | Avg Train KL Loss: 1585.4140\n",
      "Epoch 177 Validation | Avg Val Loss: 128.4068 | Avg Val Recon Loss: 126.6380 | Avg Val KL Loss: 1768.7606\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 178 Complete | Avg Train Loss: 131.1369 | Avg Train Recon Loss: 129.5030 | Avg Train KL Loss: 1633.9271\n",
      "Epoch 178 Validation | Avg Val Loss: 127.9825 | Avg Val Recon Loss: 126.2052 | Avg Val KL Loss: 1777.3328\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 179 Complete | Avg Train Loss: 129.5731 | Avg Train Recon Loss: 127.9273 | Avg Train KL Loss: 1645.7877\n",
      "Epoch 179 Validation | Avg Val Loss: 121.9542 | Avg Val Recon Loss: 120.1861 | Avg Val KL Loss: 1768.1463\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 180 Complete | Avg Train Loss: 131.6933 | Avg Train Recon Loss: 130.0980 | Avg Train KL Loss: 1595.3311\n",
      "Epoch 180 Validation | Avg Val Loss: 129.6709 | Avg Val Recon Loss: 127.9849 | Avg Val KL Loss: 1685.9951\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 181 Complete | Avg Train Loss: 133.9582 | Avg Train Recon Loss: 132.3672 | Avg Train KL Loss: 1590.9662\n",
      "Epoch 181 Validation | Avg Val Loss: 123.7686 | Avg Val Recon Loss: 122.0248 | Avg Val KL Loss: 1743.7797\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 182 Complete | Avg Train Loss: 128.8135 | Avg Train Recon Loss: 127.1715 | Avg Train KL Loss: 1642.0278\n",
      "Epoch 182 Validation | Avg Val Loss: 119.6880 | Avg Val Recon Loss: 117.9057 | Avg Val KL Loss: 1782.2526\n",
      "✔ 最佳模型已保存，验证损失: 119.6880\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 183 Complete | Avg Train Loss: 126.0789 | Avg Train Recon Loss: 124.4173 | Avg Train KL Loss: 1661.5415\n",
      "Epoch 183 Validation | Avg Val Loss: 117.4213 | Avg Val Recon Loss: 115.6154 | Avg Val KL Loss: 1805.9372\n",
      "✔ 最佳模型已保存，验证损失: 117.4213\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 184 Complete | Avg Train Loss: 124.5643 | Avg Train Recon Loss: 122.9182 | Avg Train KL Loss: 1646.0498\n",
      "Epoch 184 Validation | Avg Val Loss: 116.4564 | Avg Val Recon Loss: 114.6991 | Avg Val KL Loss: 1757.3147\n",
      "✔ 最佳模型已保存，验证损失: 116.4564\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 185 Complete | Avg Train Loss: 127.7087 | Avg Train Recon Loss: 126.1088 | Avg Train KL Loss: 1599.8979\n",
      "Epoch 185 Validation | Avg Val Loss: 140.7917 | Avg Val Recon Loss: 139.1512 | Avg Val KL Loss: 1640.4598\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 186 Complete | Avg Train Loss: 136.0881 | Avg Train Recon Loss: 134.5159 | Avg Train KL Loss: 1572.2491\n",
      "Epoch 186 Validation | Avg Val Loss: 144.9358 | Avg Val Recon Loss: 143.2326 | Avg Val KL Loss: 1703.1918\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 187 Complete | Avg Train Loss: 139.3317 | Avg Train Recon Loss: 137.7314 | Avg Train KL Loss: 1600.3381\n",
      "Epoch 187 Validation | Avg Val Loss: 152.5142 | Avg Val Recon Loss: 150.8159 | Avg Val KL Loss: 1698.2931\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 188 Complete | Avg Train Loss: 139.1360 | Avg Train Recon Loss: 137.4407 | Avg Train KL Loss: 1695.3499\n",
      "Epoch 188 Validation | Avg Val Loss: 134.2333 | Avg Val Recon Loss: 132.4002 | Avg Val KL Loss: 1833.0430\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 189 Complete | Avg Train Loss: 131.8878 | Avg Train Recon Loss: 130.1204 | Avg Train KL Loss: 1767.4115\n",
      "Epoch 189 Validation | Avg Val Loss: 133.9111 | Avg Val Recon Loss: 132.1085 | Avg Val KL Loss: 1802.6176\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 190 Complete | Avg Train Loss: 131.3303 | Avg Train Recon Loss: 129.6365 | Avg Train KL Loss: 1693.7276\n",
      "Epoch 190 Validation | Avg Val Loss: 147.5113 | Avg Val Recon Loss: 145.7288 | Avg Val KL Loss: 1782.5536\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 191 Complete | Avg Train Loss: 143.4430 | Avg Train Recon Loss: 141.7230 | Avg Train KL Loss: 1720.0022\n",
      "Epoch 191 Validation | Avg Val Loss: 144.2018 | Avg Val Recon Loss: 142.4872 | Avg Val KL Loss: 1714.5804\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 192 Complete | Avg Train Loss: 135.7029 | Avg Train Recon Loss: 134.0711 | Avg Train KL Loss: 1631.8200\n",
      "Epoch 192 Validation | Avg Val Loss: 125.6851 | Avg Val Recon Loss: 123.8706 | Avg Val KL Loss: 1814.4811\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 193 Complete | Avg Train Loss: 127.9929 | Avg Train Recon Loss: 126.3123 | Avg Train KL Loss: 1680.6777\n",
      "Epoch 193 Validation | Avg Val Loss: 120.1680 | Avg Val Recon Loss: 118.4089 | Avg Val KL Loss: 1759.0505\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 194 Complete | Avg Train Loss: 125.3625 | Avg Train Recon Loss: 123.7030 | Avg Train KL Loss: 1659.4911\n",
      "Epoch 194 Validation | Avg Val Loss: 116.3978 | Avg Val Recon Loss: 114.6233 | Avg Val KL Loss: 1774.4517\n",
      "✔ 最佳模型已保存，验证损失: 116.3978\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 195 Complete | Avg Train Loss: 124.4658 | Avg Train Recon Loss: 122.8439 | Avg Train KL Loss: 1621.9190\n",
      "Epoch 195 Validation | Avg Val Loss: 119.5088 | Avg Val Recon Loss: 117.8124 | Avg Val KL Loss: 1696.4722\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 196 Complete | Avg Train Loss: 124.3460 | Avg Train Recon Loss: 122.7817 | Avg Train KL Loss: 1564.3395\n",
      "Epoch 196 Validation | Avg Val Loss: 116.1655 | Avg Val Recon Loss: 114.5021 | Avg Val KL Loss: 1663.4299\n",
      "✔ 最佳模型已保存，验证损失: 116.1655\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 197 Complete | Avg Train Loss: 121.9457 | Avg Train Recon Loss: 120.3953 | Avg Train KL Loss: 1550.3720\n",
      "Epoch 197 Validation | Avg Val Loss: 115.8297 | Avg Val Recon Loss: 114.1592 | Avg Val KL Loss: 1670.5394\n",
      "✔ 最佳模型已保存，验证损失: 115.8297\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 198 Complete | Avg Train Loss: 121.5617 | Avg Train Recon Loss: 120.0411 | Avg Train KL Loss: 1520.5720\n",
      "Epoch 198 Validation | Avg Val Loss: 116.1618 | Avg Val Recon Loss: 114.5430 | Avg Val KL Loss: 1618.8305\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 199 Complete | Avg Train Loss: 120.8898 | Avg Train Recon Loss: 119.3756 | Avg Train KL Loss: 1514.1434\n",
      "Epoch 199 Validation | Avg Val Loss: 117.7308 | Avg Val Recon Loss: 116.1440 | Avg Val KL Loss: 1586.8182\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "Epoch 200 Complete | Avg Train Loss: 121.1440 | Avg Train Recon Loss: 119.6510 | Avg Train KL Loss: 1493.0033\n",
      "Epoch 200 Validation | Avg Val Loss: 115.9253 | Avg Val Recon Loss: 114.3528 | Avg Val KL Loss: 1572.4579\n",
      "Scaler 已保存到 scaler_segmented.pkl\n",
      "训练完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, d_model=128, nhead=4, num_layers=2, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len=seq_len)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True) # Use batch_first\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # Output of encoder will be (batch_size, seq_len, d_model)\n",
    "        self.fc_mu = nn.Linear(d_model * seq_len, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(d_model * seq_len, latent_dim)\n",
    "        \n",
    "        self.fc_latent_to_d_model = nn.Linear(latent_dim, d_model) # Project latent_dim to d_model for decoder initial input\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, batch_first=True) # Use batch_first\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.output_linear = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B, L, D_input)\n",
    "        h = self.input_linear(x) # (B, L, d_model)\n",
    "        h_with_pos = self.pos_enc(h) # (B, L, d_model)\n",
    "        \n",
    "        # TransformerEncoder expects (batch_size, seq_len, features) with batch_first=True\n",
    "        encoder_output = self.encoder(h_with_pos) # (B, L, d_model)\n",
    "        \n",
    "        # Flatten the encoder output for mu and logvar layers\n",
    "        flat_encoder_output = encoder_output.contiguous().view(encoder_output.size(0), -1)\n",
    "        \n",
    "        mu = self.fc_mu(flat_encoder_output)\n",
    "        logvar = self.fc_logvar(flat_encoder_output)\n",
    "        \n",
    "        return mu, logvar, encoder_output # Return encoder_output as memory\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, encoder_memory):\n",
    "        # z: (B, latent_dim)\n",
    "        # encoder_memory: (B, L, d_model) from encoder output\n",
    "\n",
    "        # Create the initial target sequence for the decoder.\n",
    "        # This is crucial for sequence generation.\n",
    "        # A common approach for VAEs is to project the latent 'z'\n",
    "        # and repeat it for all time steps to form the target sequence,\n",
    "        # or use a special start token.\n",
    "        \n",
    "        # Here, we project z to d_model, then expand it to seq_len for simplicity.\n",
    "        # This assumes 'z' contains all information for the sequence generation.\n",
    "        # A more complex setup might involve an explicit <SOS> token.\n",
    "        \n",
    "        # Project latent 'z' to d_model for each time step\n",
    "        # (B, latent_dim) -> (B, d_model) -> expand to (B, seq_len, d_model)\n",
    "        initial_tgt_input = self.fc_latent_to_d_model(z).unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "        \n",
    "        # Add positional encoding to the initial target sequence\n",
    "        tgt_with_pos = self.pos_enc(initial_tgt_input) # (B, L, d_model)\n",
    "        \n",
    "        # Decoder takes (tgt, memory). Both should be (B, L, D) with batch_first=True\n",
    "        # For standard Transformer Decoder, tgt is the sequence being built, and memory is from encoder.\n",
    "        # Here, we use a fixed initial_tgt_input as the query for the decoder.\n",
    "        out = self.decoder(tgt_with_pos, encoder_memory) # (B, L, d_model)\n",
    "        \n",
    "        return self.output_linear(out) # (B, L, input_dim)\n",
    "\n",
    "\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, data_list, max_seq_len, input_dim, scaler=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): 包含所有 STS 序列 numpy 数组的列表。\n",
    "                              每个数组应已处理为 (original_len, input_dim)。\n",
    "            max_seq_len (int): 序列的最大长度。\n",
    "            input_dim (int): 每个时间步的特征维度 (e.g., 50 for 25 keypoints).\n",
    "            scaler (sklearn.preprocessing.Scaler): 用于归一化的 scaler 对象，\n",
    "                                                 训练时传入 None，测试时传入训练好的 scaler。\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.scaler = scaler\n",
    "\n",
    "        if self.scaler is None:\n",
    "            print(\"Fitting scaler on entire dataset for normalization...\")\n",
    "            all_data = np.vstack([seq for seq in data_list])\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.scaler.fit(all_data)\n",
    "            print(\"Scaler fitted.\")\n",
    "        \n",
    "        self.processed_data = []\n",
    "        for seq_np in self.data_list:\n",
    "            normalized_seq = self.scaler.transform(seq_np)\n",
    "\n",
    "            if normalized_seq.shape[0] < self.max_seq_len:\n",
    "                pad = np.zeros((self.max_seq_len - normalized_seq.shape[0], self.input_dim), dtype=np.float32)\n",
    "                processed_seq = np.vstack([normalized_seq, pad])\n",
    "            else:\n",
    "                processed_seq = normalized_seq[:self.max_seq_len]\n",
    "            self.processed_data.append(torch.tensor(processed_seq, dtype=torch.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx]\n",
    "\n",
    "    def get_scaler(self):\n",
    "        return self.scaler\n",
    "\n",
    "SCALER_SAVE_PATH = 'scaler_segmented.pkl'\n",
    "\n",
    "NUM_KPT = 25\n",
    "\n",
    "D_MODEL = 128\n",
    "NHEAD = 4\n",
    "NUM_LAYERS = 2\n",
    "LATENT_DIM = 64\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='sum') # reduction='sum' for KL divergence\n",
    "    \n",
    "    # D_KL = -0.5 * sum(1 + log_sigma^2 - mu^2 - sigma^2)\n",
    "    KL_D = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return MSE + beta * KL_D, MSE, KL_D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_vae_model():\n",
    "    print(\"加载并预处理所有 STS 关键点数据...\")\n",
    "    all_sequences = []\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(DATA_DIR, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, header=2, engine='python', on_bad_lines='skip')\n",
    "                keypoint_data = df.iloc[:, 2:2+INPUT_DIM].to_numpy(dtype=np.float32)\n",
    "                    all_sequences.append(keypoint_data)\n",
    "                else:\n",
    "                    print(f\"Skipping empty or malformed file: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_sequences:\n",
    "        print(\"未找到任何有效的 STS 关键点数据。请检查 DATA_DIR 和 CSV 文件格式。\")\n",
    "        return\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(\n",
    "        all_sequences, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"训练序列数量: {len(train_sequences)}, 验证序列数量: {len(val_sequences)}\")\n",
    "\n",
    "    train_dataset = KeypointDataset(train_sequences, SEQ_LEN, INPUT_DIM)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(\"初始化模型...\")\n",
    "    model = TransformerVAE(INPUT_DIM, SEQ_LEN, D_MODEL, NHEAD, NUM_LAYERS, LATENT_DIM).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"开始训练模型...\")\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_recon_loss = 0\n",
    "        train_kl_loss = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(DEVICE) # (B, L, D)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mu, logvar, encoder_output = model.encode(data)\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "            \n",
    "            loss, recon_loss_val, kl_loss_val = vae_loss(recon_batch, data, mu, logvar)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_recon_loss += recon_loss_val.item()\n",
    "            train_kl_loss += kl_loss_val.item()\n",
    "\n",
    "            if (batch_idx + 1) % LOG_INTERVAL == 0:\n",
    "                print(f\"Epoch {epoch+1}/{EPOCHS}, Batch {batch_idx+1}/{len(train_loader)} | \"\n",
    "                      f\"Train Loss: {train_loss / (batch_idx+1):.4f} | \"\n",
    "                      f\"Recon Loss: {train_recon_loss / (batch_idx+1):.4f} | \"\n",
    "                      f\"KL Loss: {train_kl_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "        avg_train_recon_loss = train_recon_loss / len(train_loader.dataset)\n",
    "        avg_train_kl_loss = train_kl_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1} Complete | Avg Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Avg Train Recon Loss: {avg_train_recon_loss:.4f} | \"\n",
    "              f\"Avg Train KL Loss: {avg_train_kl_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_recon_loss = 0\n",
    "        val_kl_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(DEVICE)\n",
    "                mu, logvar, encoder_output = model.encode(data)\n",
    "                z = model.reparameterize(mu, logvar)\n",
    "                \n",
    "                loss, recon_loss_val, kl_loss_val = vae_loss(recon_batch, data, mu, logvar)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_recon_loss += recon_loss_val.item()\n",
    "                val_kl_loss += kl_loss_val.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        avg_val_recon_loss = val_recon_loss / len(val_loader.dataset)\n",
    "        avg_val_kl_loss = val_kl_loss / len(val_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1} Validation | Avg Val Loss: {avg_val_loss:.4f} | \"\n",
    "              f\"Avg Val Recon Loss: {avg_val_recon_loss:.4f} | \"\n",
    "              f\"Avg Val KL Loss: {avg_val_kl_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"✔ 最佳模型已保存，验证损失: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "        with open(SCALER_SAVE_PATH, 'wb') as f:\n",
    "        print(f\"Scaler 已保存到 {SCALER_SAVE_PATH}\")\n",
    "\n",
    "    print(\"训练完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_vae_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4fd85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 训练脚本内部测试：模型权重加载成功，文件有效！\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    temp_model = TransformerVAE(INPUT_DIM, SEQ_LEN, D_MODEL, NHEAD, NUM_LAYERS, LATENT_DIM).to(DEVICE)\n",
    "    temp_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE, weights_only=True))\n",
    "    print(\"✔ 训练脚本内部测试：模型权重加载成功，文件有效！\")\n",
    "except Exception as e:\n",
    "    print(f\" 训练脚本内部测试：模型权重加载失败！文件可能损坏或与模型定义不匹配: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7b3db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6954fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "开始批量处理CSV文件...\n",
      "找到 404 个匹配文件\n",
      "\n",
      "正在处理第 1/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_301.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_301_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 2/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_301_synthetic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (505, 52)\n",
      "原始数据长度: 505\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (505, 2), Full synth shape: (505, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_301_synthetic_synthetic.csv （shape=(505, 52)）\n",
      "\n",
      "正在处理第 3/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_305.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_305_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 4/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_306.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_306_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 5/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_307.csv\n",
      "CSV 文件读取完成，形状为: (101, 52)\n",
      "原始数据长度: 101\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (101, 2), Full synth shape: (101, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_307_synthetic.csv （shape=(101, 52)）\n",
      "\n",
      "正在处理第 6/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_316.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_316_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 7/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_317.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_317_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 8/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_318.csv\n",
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_318_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 9/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_319.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_319_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 10/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_320.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_320_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 11/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_321.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_321_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 12/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_322.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_322_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 13/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_323.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_323_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 14/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_325.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_325_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 15/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_327.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_327_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 16/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_328.csv\n",
      "CSV 文件读取完成，形状为: (89, 52)\n",
      "原始数据长度: 89\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (89, 2), Full synth shape: (89, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_328_synthetic.csv （shape=(89, 52)）\n",
      "\n",
      "正在处理第 17/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_33.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_33_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 18/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_34.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_34_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 19/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_35.csv\n",
      "CSV 文件读取完成，形状为: (417, 52)\n",
      "原始数据长度: 417\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (417, 2), Full synth shape: (417, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_35_synthetic.csv （shape=(417, 52)）\n",
      "\n",
      "正在处理第 20/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_36.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_36_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 21/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_37.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_37_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 22/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_39.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_39_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 23/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_44.csv\n",
      "CSV 文件读取完成，形状为: (287, 52)\n",
      "原始数据长度: 287\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (287, 2), Full synth shape: (287, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_44_synthetic.csv （shape=(287, 52)）\n",
      "\n",
      "正在处理第 24/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_45.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_45_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 25/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_375.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_375_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 26/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_376.csv\n",
      "CSV 文件读取完成，形状为: (328, 52)\n",
      "原始数据长度: 328\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (328, 2), Full synth shape: (328, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_376_synthetic.csv （shape=(328, 52)）\n",
      "\n",
      "正在处理第 27/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_379.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_379_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 28/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_380.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_380_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 29/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_386.csv\n",
      "CSV 文件读取完成，形状为: (219, 52)\n",
      "原始数据长度: 219\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (219, 2), Full synth shape: (219, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_386_synthetic.csv （shape=(219, 52)）\n",
      "\n",
      "正在处理第 30/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_387.csv\n",
      "CSV 文件读取完成，形状为: (158, 52)\n",
      "原始数据长度: 158\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (158, 2), Full synth shape: (158, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_387_synthetic.csv （shape=(158, 52)）\n",
      "\n",
      "正在处理第 31/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_389.csv\n",
      "CSV 文件读取完成，形状为: (355, 52)\n",
      "原始数据长度: 355\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (355, 2), Full synth shape: (355, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_389_synthetic.csv （shape=(355, 52)）\n",
      "\n",
      "正在处理第 32/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_390.csv\n",
      "CSV 文件读取完成，形状为: (412, 52)\n",
      "原始数据长度: 412\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (412, 2), Full synth shape: (412, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_390_synthetic.csv （shape=(412, 52)）\n",
      "\n",
      "正在处理第 33/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_392.csv\n",
      "CSV 文件读取完成，形状为: (52, 52)\n",
      "原始数据长度: 52\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (52, 2), Full synth shape: (52, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_392_synthetic.csv （shape=(52, 52)）\n",
      "\n",
      "正在处理第 34/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_398.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_398_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 35/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_399.csv\n",
      "CSV 文件读取完成，形状为: (250, 52)\n",
      "原始数据长度: 250\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (250, 2), Full synth shape: (250, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_399_synthetic.csv （shape=(250, 52)）\n",
      "\n",
      "正在处理第 36/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_400.csv\n",
      "CSV 文件读取完成，形状为: (148, 52)\n",
      "原始数据长度: 148\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (148, 2), Full synth shape: (148, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_400_synthetic.csv （shape=(148, 52)）\n",
      "\n",
      "正在处理第 37/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_401.csv\n",
      "CSV 文件读取完成，形状为: (239, 52)\n",
      "原始数据长度: 239\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (239, 2), Full synth shape: (239, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_401_synthetic.csv （shape=(239, 52)）\n",
      "\n",
      "正在处理第 38/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_403.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_403_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 39/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_404.csv\n",
      "CSV 文件读取完成，形状为: (72, 52)\n",
      "原始数据长度: 72\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (72, 2), Full synth shape: (72, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_404_synthetic.csv （shape=(72, 52)）\n",
      "\n",
      "正在处理第 40/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_405.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_405_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 41/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_406.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_406_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 42/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_407.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_407_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 43/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_416.csv\n",
      "CSV 文件读取完成，形状为: (185, 52)\n",
      "原始数据长度: 185\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (185, 2), Full synth shape: (185, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_416_synthetic.csv （shape=(185, 52)）\n",
      "\n",
      "正在处理第 44/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_417.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_417_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 45/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_418.csv\n",
      "CSV 文件读取完成，形状为: (371, 52)\n",
      "原始数据长度: 371\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (371, 2), Full synth shape: (371, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_418_synthetic.csv （shape=(371, 52)）\n",
      "\n",
      "正在处理第 46/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_420.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_420_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 47/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_421.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_421_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 48/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_422.csv\n",
      "CSV 文件读取完成，形状为: (132, 52)\n",
      "原始数据长度: 132\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (132, 2), Full synth shape: (132, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_422_synthetic.csv （shape=(132, 52)）\n",
      "\n",
      "正在处理第 49/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_424.csv\n",
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_424_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 50/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_426.csv\n",
      "CSV 文件读取完成，形状为: (155, 52)\n",
      "原始数据长度: 155\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (155, 2), Full synth shape: (155, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_426_synthetic.csv （shape=(155, 52)）\n",
      "\n",
      "正在处理第 51/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_428.csv\n",
      "CSV 文件读取完成，形状为: (184, 52)\n",
      "原始数据长度: 184\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (184, 2), Full synth shape: (184, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_428_synthetic.csv （shape=(184, 52)）\n",
      "\n",
      "正在处理第 52/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_429.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_429_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 53/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_430.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (244, 52)\n",
      "原始数据长度: 244\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (244, 2), Full synth shape: (244, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_430_synthetic.csv （shape=(244, 52)）\n",
      "\n",
      "正在处理第 54/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_434.csv\n",
      "CSV 文件读取完成，形状为: (372, 52)\n",
      "原始数据长度: 372\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (372, 2), Full synth shape: (372, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_434_synthetic.csv （shape=(372, 52)）\n",
      "\n",
      "正在处理第 55/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_698.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_698_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 56/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_699.csv\n",
      "CSV 文件读取完成，形状为: (398, 52)\n",
      "原始数据长度: 398\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (398, 2), Full synth shape: (398, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_699_synthetic.csv （shape=(398, 52)）\n",
      "\n",
      "正在处理第 57/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_700.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_700_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 58/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_701.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_701_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 59/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_702.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_702_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 60/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_703.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_703_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 61/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_705.csv\n",
      "CSV 文件读取完成，形状为: (152, 52)\n",
      "原始数据长度: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (152, 2), Full synth shape: (152, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_705_synthetic.csv （shape=(152, 52)）\n",
      "\n",
      "正在处理第 62/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_709.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_709_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 63/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_712.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_712_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 64/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_717.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_717_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 65/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_718.csv\n",
      "CSV 文件读取完成，形状为: (414, 52)\n",
      "原始数据长度: 414\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (414, 2), Full synth shape: (414, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_718_synthetic.csv （shape=(414, 52)）\n",
      "\n",
      "正在处理第 66/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_719.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_719_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 67/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_720.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_720_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 68/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_721.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_721_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 69/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_722.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_722_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 70/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_723.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_723_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 71/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_724.csv\n",
      "CSV 文件读取完成，形状为: (257, 52)\n",
      "原始数据长度: 257\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (257, 2), Full synth shape: (257, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_724_synthetic.csv （shape=(257, 52)）\n",
      "\n",
      "正在处理第 72/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_725.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_725_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 73/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_726.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_726_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 74/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_101.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_101_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 75/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_50.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_50_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 76/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_51.csv\n",
      "CSV 文件读取完成，形状为: (234, 52)\n",
      "原始数据长度: 234\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (234, 2), Full synth shape: (234, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_51_synthetic.csv （shape=(234, 52)）\n",
      "\n",
      "正在处理第 77/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_52.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_52_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 78/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_53.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_53_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 79/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_54.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_54_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 80/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_55.csv\n",
      "CSV 文件读取完成，形状为: (170, 52)\n",
      "原始数据长度: 170\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (170, 2), Full synth shape: (170, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_55_synthetic.csv （shape=(170, 52)）\n",
      "\n",
      "正在处理第 81/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_56.csv\n",
      "CSV 文件读取完成，形状为: (271, 52)\n",
      "原始数据长度: 271\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (271, 2), Full synth shape: (271, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_56_synthetic.csv （shape=(271, 52)）\n",
      "\n",
      "正在处理第 82/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_57.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_57_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 83/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_62.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_62_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 84/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_63.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_63_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 85/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_64.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_64_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 86/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_71.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_71_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 87/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_73.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_73_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 88/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_75.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_75_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 89/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_76.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_76_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 90/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_77.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_77_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 91/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_78.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_78_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 92/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_79.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_79_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 93/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_80.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_80_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 94/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_81.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_81_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 95/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_86.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_86_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 96/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_87.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_87_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 97/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_89.csv\n",
      "CSV 文件读取完成，形状为: (320, 52)\n",
      "原始数据长度: 320\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (320, 2), Full synth shape: (320, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_89_synthetic.csv （shape=(320, 52)）\n",
      "\n",
      "正在处理第 98/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_90.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_90_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 99/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_91.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_91_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 100/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_438.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_438_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 101/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_439.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_439_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 102/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_440.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_440_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 103/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_441.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_441_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 104/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_447.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_447_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 105/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_451.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_451_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 106/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_452.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_452_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 107/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_454.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_454_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 108/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_455.csv\n",
      "CSV 文件读取完成，形状为: (142, 52)\n",
      "原始数据长度: 142\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (142, 2), Full synth shape: (142, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_455_synthetic.csv （shape=(142, 52)）\n",
      "\n",
      "正在处理第 109/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_459.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_459_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 110/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_460.csv\n",
      "CSV 文件读取完成，形状为: (148, 52)\n",
      "原始数据长度: 148\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (148, 2), Full synth shape: (148, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_460_synthetic.csv （shape=(148, 52)）\n",
      "\n",
      "正在处理第 111/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_461.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_461_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 112/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_462.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_462_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 113/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_463.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_463_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 114/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_102.csv\n",
      "CSV 文件读取完成，形状为: (295, 52)\n",
      "原始数据长度: 295\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (295, 2), Full synth shape: (295, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_102_synthetic.csv （shape=(295, 52)）\n",
      "\n",
      "正在处理第 115/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_103.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_103_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 116/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_104.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_104_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 117/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_105.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_105_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 118/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_108.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_108_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 119/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_109.csv\n",
      "CSV 文件读取完成，形状为: (88, 52)\n",
      "原始数据长度: 88\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (88, 2), Full synth shape: (88, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_109_synthetic.csv （shape=(88, 52)）\n",
      "\n",
      "正在处理第 120/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_111.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_111_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 121/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_112.csv\n",
      "CSV 文件读取完成，形状为: (140, 52)\n",
      "原始数据长度: 140\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (140, 2), Full synth shape: (140, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_112_synthetic.csv （shape=(140, 52)）\n",
      "\n",
      "正在处理第 122/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_115.csv\n",
      "CSV 文件读取完成，形状为: (426, 52)\n",
      "原始数据长度: 426\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (426, 2), Full synth shape: (426, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_115_synthetic.csv （shape=(426, 52)）\n",
      "\n",
      "正在处理第 123/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_117.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_117_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 124/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_118.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_118_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 125/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_119.csv\n",
      "CSV 文件读取完成，形状为: (24, 52)\n",
      "原始数据长度: 24\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (24, 2), Full synth shape: (24, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_119_synthetic.csv （shape=(24, 52)）\n",
      "\n",
      "正在处理第 126/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_754.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_754_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 127/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_756.csv\n",
      "CSV 文件读取完成，形状为: (125, 52)\n",
      "原始数据长度: 125\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (125, 2), Full synth shape: (125, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_756_synthetic.csv （shape=(125, 52)）\n",
      "\n",
      "正在处理第 128/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_759.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_759_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 129/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_762.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_762_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 130/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_763.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_763_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 131/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_764.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_764_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 132/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_765.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_765_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 133/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_766.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_766_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 134/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_767.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_767_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 135/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_770.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_770_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 136/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_771.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_771_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 137/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_772.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_772_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 138/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_773.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_773_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 139/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_774.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_774_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 140/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_777.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_777_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 141/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_778.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_778_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 142/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_779.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_779_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 143/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_780.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_780_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 144/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_267.csv\n",
      "CSV 文件读取完成，形状为: (324, 52)\n",
      "原始数据长度: 324\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (324, 2), Full synth shape: (324, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_267_synthetic.csv （shape=(324, 52)）\n",
      "\n",
      "正在处理第 145/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_268.csv\n",
      "CSV 文件读取完成，形状为: (175, 52)\n",
      "原始数据长度: 175\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (175, 2), Full synth shape: (175, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_268_synthetic.csv （shape=(175, 52)）\n",
      "\n",
      "正在处理第 146/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_270.csv\n",
      "CSV 文件读取完成，形状为: (86, 52)\n",
      "原始数据长度: 86\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (86, 2), Full synth shape: (86, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_270_synthetic.csv （shape=(86, 52)）\n",
      "\n",
      "正在处理第 147/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_272.csv\n",
      "CSV 文件读取完成，形状为: (309, 52)\n",
      "原始数据长度: 309\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (309, 2), Full synth shape: (309, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_272_synthetic.csv （shape=(309, 52)）\n",
      "\n",
      "正在处理第 148/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_274.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_274_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 149/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_275.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_275_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 150/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_276.csv\n",
      "CSV 文件读取完成，形状为: (230, 52)\n",
      "原始数据长度: 230\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (230, 2), Full synth shape: (230, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_276_synthetic.csv （shape=(230, 52)）\n",
      "\n",
      "正在处理第 151/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_278.csv\n",
      "CSV 文件读取完成，形状为: (347, 52)\n",
      "原始数据长度: 347\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (347, 2), Full synth shape: (347, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_278_synthetic.csv （shape=(347, 52)）\n",
      "\n",
      "正在处理第 152/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_279.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_279_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 153/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_280.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_280_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 154/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_281.csv\n",
      "CSV 文件读取完成，形状为: (474, 52)\n",
      "原始数据长度: 474\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (474, 2), Full synth shape: (474, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_281_synthetic.csv （shape=(474, 52)）\n",
      "\n",
      "正在处理第 155/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_283.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_283_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 156/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_284.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_284_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 157/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_285.csv\n",
      "CSV 文件读取完成，形状为: (316, 52)\n",
      "原始数据长度: 316\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (316, 2), Full synth shape: (316, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_285_synthetic.csv （shape=(316, 52)）\n",
      "\n",
      "正在处理第 158/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_286.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_286_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 159/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_287.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_287_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 160/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_290.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_290_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 161/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_293.csv\n",
      "CSV 文件读取完成，形状为: (488, 52)\n",
      "原始数据长度: 488\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (488, 2), Full synth shape: (488, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_293_synthetic.csv （shape=(488, 52)）\n",
      "\n",
      "正在处理第 162/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_295.csv\n",
      "CSV 文件读取完成，形状为: (499, 52)\n",
      "原始数据长度: 499\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (499, 2), Full synth shape: (499, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_295_synthetic.csv （shape=(499, 52)）\n",
      "\n",
      "正在处理第 163/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_296.csv\n",
      "CSV 文件读取完成，形状为: (419, 52)\n",
      "原始数据长度: 419\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (419, 2), Full synth shape: (419, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_296_synthetic.csv （shape=(419, 52)）\n",
      "\n",
      "正在处理第 164/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_299.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_299_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 165/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_633.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_633_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 166/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_634.csv\n",
      "CSV 文件读取完成，形状为: (413, 52)\n",
      "原始数据长度: 413\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (413, 2), Full synth shape: (413, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_634_synthetic.csv （shape=(413, 52)）\n",
      "\n",
      "正在处理第 167/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_636.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_636_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 168/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_645.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_645_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 169/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_646.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_646_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 170/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_647.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_647_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 171/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_648.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_648_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 172/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_649.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_649_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 173/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_650.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_650_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 174/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_651.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_651_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 175/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_653.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_653_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 176/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_464.csv\n",
      "CSV 文件读取完成，形状为: (213, 52)\n",
      "原始数据长度: 213\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (213, 2), Full synth shape: (213, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_464_synthetic.csv （shape=(213, 52)）\n",
      "\n",
      "正在处理第 177/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_465.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_465_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 178/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_473.csv\n",
      "CSV 文件读取完成，形状为: (109, 52)\n",
      "原始数据长度: 109\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (109, 2), Full synth shape: (109, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_473_synthetic.csv （shape=(109, 52)）\n",
      "\n",
      "正在处理第 179/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_474.csv\n",
      "CSV 文件读取完成，形状为: (167, 52)\n",
      "原始数据长度: 167\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (167, 2), Full synth shape: (167, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_474_synthetic.csv （shape=(167, 52)）\n",
      "\n",
      "正在处理第 180/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_475.csv\n",
      "CSV 文件读取完成，形状为: (226, 52)\n",
      "原始数据长度: 226\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (226, 2), Full synth shape: (226, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_475_synthetic.csv （shape=(226, 52)）\n",
      "\n",
      "正在处理第 181/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_476.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_476_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 182/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_477.csv\n",
      "CSV 文件读取完成，形状为: (264, 52)\n",
      "原始数据长度: 264\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (264, 2), Full synth shape: (264, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_477_synthetic.csv （shape=(264, 52)）\n",
      "\n",
      "正在处理第 183/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_479.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_479_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 184/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_480.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_480_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 185/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_481.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_481_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 186/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_482.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_482_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 187/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_121.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_121_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 188/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_122.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_122_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 189/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_125.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_125_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 190/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_126.csv\n",
      "CSV 文件读取完成，形状为: (198, 52)\n",
      "原始数据长度: 198\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (198, 2), Full synth shape: (198, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_126_synthetic.csv （shape=(198, 52)）\n",
      "\n",
      "正在处理第 191/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_127.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_127_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 192/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_128.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_128_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 193/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_143.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_143_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 194/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_157.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_157_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 195/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_158.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_158_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 196/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_159.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_159_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 197/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_160.csv\n",
      "CSV 文件读取完成，形状为: (430, 52)\n",
      "原始数据长度: 430\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (430, 2), Full synth shape: (430, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_160_synthetic.csv （shape=(430, 52)）\n",
      "\n",
      "正在处理第 198/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_161.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_161_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 199/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_162.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_162_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 200/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_174.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_174_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 201/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_178.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_178_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 202/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_179.csv\n",
      "CSV 文件读取完成，形状为: (176, 52)\n",
      "原始数据长度: 176\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (176, 2), Full synth shape: (176, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_179_synthetic.csv （shape=(176, 52)）\n",
      "\n",
      "正在处理第 203/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_180.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_180_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 204/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_181.csv\n",
      "CSV 文件读取完成，形状为: (252, 52)\n",
      "原始数据长度: 252\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (252, 2), Full synth shape: (252, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_181_synthetic.csv （shape=(252, 52)）\n",
      "\n",
      "正在处理第 205/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_182.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_182_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 206/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_184.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_184_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 207/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_187.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_187_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 208/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_188.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_188_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 209/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_189.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_189_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 210/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_190.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_190_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 211/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_192.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_192_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 212/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_198.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_198_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 213/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_199.csv\n",
      "CSV 文件读取完成，形状为: (504, 52)\n",
      "原始数据长度: 504\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (504, 2), Full synth shape: (504, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_199_synthetic.csv （shape=(504, 52)）\n",
      "\n",
      "正在处理第 214/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_200.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_200_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 215/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_201.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_201_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 216/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_203.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_203_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 217/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_204.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_204_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 218/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_205.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_205_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 219/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_206.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_206_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 220/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_728.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_728_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 221/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_729.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_729_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 222/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_730.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_730_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 223/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_731.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_731_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 224/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_732.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_732_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 225/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_736.csv\n",
      "CSV 文件读取完成，形状为: (194, 52)\n",
      "原始数据长度: 194\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (194, 2), Full synth shape: (194, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_736_synthetic.csv （shape=(194, 52)）\n",
      "\n",
      "正在处理第 226/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_737.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_737_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 227/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_751.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_751_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 228/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_486.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_486_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 229/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_487.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_487_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 230/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_488.csv\n",
      "CSV 文件读取完成，形状为: (403, 52)\n",
      "原始数据长度: 403\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (403, 2), Full synth shape: (403, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_488_synthetic.csv （shape=(403, 52)）\n",
      "\n",
      "正在处理第 231/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_489.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_489_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 232/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_490.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_490_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 233/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_491.csv\n",
      "CSV 文件读取完成，形状为: (108, 52)\n",
      "原始数据长度: 108\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (108, 2), Full synth shape: (108, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_491_synthetic.csv （shape=(108, 52)）\n",
      "\n",
      "正在处理第 234/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_493.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_493_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 235/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_495.csv\n",
      "CSV 文件读取完成，形状为: (59, 52)\n",
      "原始数据长度: 59\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (59, 2), Full synth shape: (59, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_495_synthetic.csv （shape=(59, 52)）\n",
      "\n",
      "正在处理第 236/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_497.csv\n",
      "CSV 文件读取完成，形状为: (107, 52)\n",
      "原始数据长度: 107\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (107, 2), Full synth shape: (107, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_497_synthetic.csv （shape=(107, 52)）\n",
      "\n",
      "正在处理第 237/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_499.csv\n",
      "CSV 文件读取完成，形状为: (120, 52)\n",
      "原始数据长度: 120\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (120, 2), Full synth shape: (120, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_499_synthetic.csv （shape=(120, 52)）\n",
      "\n",
      "正在处理第 238/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_501.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_501_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 239/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_502_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 240/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_503.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_503_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 241/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_504.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (462, 52)\n",
      "原始数据长度: 462\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (462, 2), Full synth shape: (462, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_504_synthetic.csv （shape=(462, 52)）\n",
      "\n",
      "正在处理第 242/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_508.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_508_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 243/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_509.csv\n",
      "CSV 文件读取完成，形状为: (491, 52)\n",
      "原始数据长度: 491\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (491, 2), Full synth shape: (491, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_509_synthetic.csv （shape=(491, 52)）\n",
      "\n",
      "正在处理第 244/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_510.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_510_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 245/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_661.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_661_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 246/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_662.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_662_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 247/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_663.csv\n",
      "CSV 文件读取完成，形状为: (449, 52)\n",
      "原始数据长度: 449\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (449, 2), Full synth shape: (449, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_663_synthetic.csv （shape=(449, 52)）\n",
      "\n",
      "正在处理第 248/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_664.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_664_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 249/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_665.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_665_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 250/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_675.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_675_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 251/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_676.csv\n",
      "CSV 文件读取完成，形状为: (347, 52)\n",
      "原始数据长度: 347\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (347, 2), Full synth shape: (347, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_676_synthetic.csv （shape=(347, 52)）\n",
      "\n",
      "正在处理第 252/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_677.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_677_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 253/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_678.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_678_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 254/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_1.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_1_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 255/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_12.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_12_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 256/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_15.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_15_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 257/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_17.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_17_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 258/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_19.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_19_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 259/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_2.csv\n",
      "CSV 文件读取完成，形状为: (401, 52)\n",
      "原始数据长度: 401\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (401, 2), Full synth shape: (401, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_2_synthetic.csv （shape=(401, 52)）\n",
      "\n",
      "正在处理第 260/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_20.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_20_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 261/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_22.csv\n",
      "CSV 文件读取完成，形状为: (425, 52)\n",
      "原始数据长度: 425\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (425, 2), Full synth shape: (425, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_22_synthetic.csv （shape=(425, 52)）\n",
      "\n",
      "正在处理第 262/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_24.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_24_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 263/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_26.csv\n",
      "CSV 文件读取完成，形状为: (136, 52)\n",
      "原始数据长度: 136\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (136, 2), Full synth shape: (136, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_26_synthetic.csv （shape=(136, 52)）\n",
      "\n",
      "正在处理第 264/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_27.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_27_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 265/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_28_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 266/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_29.csv\n",
      "CSV 文件读取完成，形状为: (394, 52)\n",
      "原始数据长度: 394\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (394, 2), Full synth shape: (394, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_29_synthetic.csv （shape=(394, 52)）\n",
      "\n",
      "正在处理第 267/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_3.csv\n",
      "CSV 文件读取完成，形状为: (384, 52)\n",
      "原始数据长度: 384\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (384, 2), Full synth shape: (384, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_3_synthetic.csv （shape=(384, 52)）\n",
      "\n",
      "正在处理第 268/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_30.csv\n",
      "CSV 文件读取完成，形状为: (440, 52)\n",
      "原始数据长度: 440\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (440, 2), Full synth shape: (440, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_30_synthetic.csv （shape=(440, 52)）\n",
      "\n",
      "正在处理第 269/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_31.csv\n",
      "CSV 文件读取完成，形状为: (100, 52)\n",
      "原始数据长度: 100\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (100, 2), Full synth shape: (100, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_31_synthetic.csv （shape=(100, 52)）\n",
      "\n",
      "正在处理第 270/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_32.csv\n",
      "CSV 文件读取完成，形状为: (97, 52)\n",
      "原始数据长度: 97\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (97, 2), Full synth shape: (97, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_32_synthetic.csv （shape=(97, 52)）\n",
      "\n",
      "正在处理第 271/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_4.csv\n",
      "CSV 文件读取完成，形状为: (425, 52)\n",
      "原始数据长度: 425\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (425, 2), Full synth shape: (425, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_4_synthetic.csv （shape=(425, 52)）\n",
      "\n",
      "正在处理第 272/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_5.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_5_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 273/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_6.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_6_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 274/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_8.csv\n",
      "CSV 文件读取完成，形状为: (262, 52)\n",
      "原始数据长度: 262\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (262, 2), Full synth shape: (262, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_8_synthetic.csv （shape=(262, 52)）\n",
      "\n",
      "正在处理第 275/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_234.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_234_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 276/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_235.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_235_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 277/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_237.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_237_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 278/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_238.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_238_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 279/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_239.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_239_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 280/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_242.csv\n",
      "CSV 文件读取完成，形状为: (165, 52)\n",
      "原始数据长度: 165\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (165, 2), Full synth shape: (165, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_242_synthetic.csv （shape=(165, 52)）\n",
      "\n",
      "正在处理第 281/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_248.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_248_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 282/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_250.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_250_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 283/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_252.csv\n",
      "CSV 文件读取完成，形状为: (353, 52)\n",
      "原始数据长度: 353\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (353, 2), Full synth shape: (353, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_252_synthetic.csv （shape=(353, 52)）\n",
      "\n",
      "正在处理第 284/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_256.csv\n",
      "CSV 文件读取完成，形状为: (210, 52)\n",
      "原始数据长度: 210\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (210, 2), Full synth shape: (210, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_256_synthetic.csv （shape=(210, 52)）\n",
      "\n",
      "正在处理第 285/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_258.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_258_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 286/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_263.csv\n",
      "CSV 文件读取完成，形状为: (374, 52)\n",
      "原始数据长度: 374\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (374, 2), Full synth shape: (374, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_263_synthetic.csv （shape=(374, 52)）\n",
      "\n",
      "正在处理第 287/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_513.csv\n",
      "CSV 文件读取完成，形状为: (498, 52)\n",
      "原始数据长度: 498\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (498, 2), Full synth shape: (498, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_513_synthetic.csv （shape=(498, 52)）\n",
      "\n",
      "正在处理第 288/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_514.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_514_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 289/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_515.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_515_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 290/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_516.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_516_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 291/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_519.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_519_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 292/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_520.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_520_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 293/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_522.csv\n",
      "CSV 文件读取完成，形状为: (165, 52)\n",
      "原始数据长度: 165\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (165, 2), Full synth shape: (165, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_522_synthetic.csv （shape=(165, 52)）\n",
      "\n",
      "正在处理第 294/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_523.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_523_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 295/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_524.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_524_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 296/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_526.csv\n",
      "CSV 文件读取完成，形状为: (309, 52)\n",
      "原始数据长度: 309\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (309, 2), Full synth shape: (309, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_526_synthetic.csv （shape=(309, 52)）\n",
      "\n",
      "正在处理第 297/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_527.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_527_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 298/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_528.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_528_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 299/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_529.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_529_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 300/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_530.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_530_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 301/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_532.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_532_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 302/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_535.csv\n",
      "CSV 文件读取完成，形状为: (171, 52)\n",
      "原始数据长度: 171\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (171, 2), Full synth shape: (171, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_535_synthetic.csv （shape=(171, 52)）\n",
      "\n",
      "正在处理第 303/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_537.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_537_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 304/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_538.csv\n",
      "CSV 文件读取完成，形状为: (443, 52)\n",
      "原始数据长度: 443\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (443, 2), Full synth shape: (443, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_538_synthetic.csv （shape=(443, 52)）\n",
      "\n",
      "正在处理第 305/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_539.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_539_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 306/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_540.csv\n",
      "CSV 文件读取完成，形状为: (446, 52)\n",
      "原始数据长度: 446\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (446, 2), Full synth shape: (446, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_540_synthetic.csv （shape=(446, 52)）\n",
      "\n",
      "正在处理第 307/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_541.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_541_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 308/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_542.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_542_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 309/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_544.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_544_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 310/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_545.csv\n",
      "CSV 文件读取完成，形状为: (82, 52)\n",
      "原始数据长度: 82\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (82, 2), Full synth shape: (82, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_545_synthetic.csv （shape=(82, 52)）\n",
      "\n",
      "正在处理第 311/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_546.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_546_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 312/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_548.csv\n",
      "CSV 文件读取完成，形状为: (460, 52)\n",
      "原始数据长度: 460\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (460, 2), Full synth shape: (460, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_548_synthetic.csv （shape=(460, 52)）\n",
      "\n",
      "正在处理第 313/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_549.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_549_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 314/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_556.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_556_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 315/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_558.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_558_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 316/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_559.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_559_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 317/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_560.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_560_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 318/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_562.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_562_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 319/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_563.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_563_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 320/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_564.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_564_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 321/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_565.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_565_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 322/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_570.csv\n",
      "CSV 文件读取完成，形状为: (299, 52)\n",
      "原始数据长度: 299\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (299, 2), Full synth shape: (299, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_570_synthetic.csv （shape=(299, 52)）\n",
      "\n",
      "正在处理第 323/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_579.csv\n",
      "CSV 文件读取完成，形状为: (298, 52)\n",
      "原始数据长度: 298\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (298, 2), Full synth shape: (298, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_579_synthetic.csv （shape=(298, 52)）\n",
      "\n",
      "正在处理第 324/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_581.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_581_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 325/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_586.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_586_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 326/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_590.csv\n",
      "CSV 文件读取完成，形状为: (432, 52)\n",
      "原始数据长度: 432\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (432, 2), Full synth shape: (432, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_590_synthetic.csv （shape=(432, 52)）\n",
      "\n",
      "正在处理第 327/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_591.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_591_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 328/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_594.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_594_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 329/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_595.csv\n",
      "CSV 文件读取完成，形状为: (402, 52)\n",
      "原始数据长度: 402\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (402, 2), Full synth shape: (402, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_595_synthetic.csv （shape=(402, 52)）\n",
      "\n",
      "正在处理第 330/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_597.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_597_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 331/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_598.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_598_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 332/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_600.csv\n",
      "CSV 文件读取完成，形状为: (180, 52)\n",
      "原始数据长度: 180\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (180, 2), Full synth shape: (180, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_600_synthetic.csv （shape=(180, 52)）\n",
      "\n",
      "正在处理第 333/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_605.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_605_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 334/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_606.csv\n",
      "CSV 文件读取完成，形状为: (170, 52)\n",
      "原始数据长度: 170\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (170, 2), Full synth shape: (170, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_606_synthetic.csv （shape=(170, 52)）\n",
      "\n",
      "正在处理第 335/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_607.csv\n",
      "CSV 文件读取完成，形状为: (276, 52)\n",
      "原始数据长度: 276\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (276, 2), Full synth shape: (276, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_607_synthetic.csv （shape=(276, 52)）\n",
      "\n",
      "正在处理第 336/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_616.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_616_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 337/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_617.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_617_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 338/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_618.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_618_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 339/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_619.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_619_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 340/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_622.csv\n",
      "CSV 文件读取完成，形状为: (224, 52)\n",
      "原始数据长度: 224\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (224, 2), Full synth shape: (224, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_622_synthetic.csv （shape=(224, 52)）\n",
      "\n",
      "正在处理第 341/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_624.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_624_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 342/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_625.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_625_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 343/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_626.csv\n",
      "CSV 文件读取完成，形状为: (312, 52)\n",
      "原始数据长度: 312\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (312, 2), Full synth shape: (312, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_626_synthetic.csv （shape=(312, 52)）\n",
      "\n",
      "正在处理第 344/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_627.csv\n",
      "CSV 文件读取完成，形状为: (306, 52)\n",
      "原始数据长度: 306\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (306, 2), Full synth shape: (306, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_627_synthetic.csv （shape=(306, 52)）\n",
      "\n",
      "正在处理第 345/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_628.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_628_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 346/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_629.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_629_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 347/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_329.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_329_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 348/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_330.csv\n",
      "CSV 文件读取完成，形状为: (152, 52)\n",
      "原始数据长度: 152\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (152, 2), Full synth shape: (152, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_330_synthetic.csv （shape=(152, 52)）\n",
      "\n",
      "正在处理第 349/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_331.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_331_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 350/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_332.csv\n",
      "CSV 文件读取完成，形状为: (412, 52)\n",
      "原始数据长度: 412\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (412, 2), Full synth shape: (412, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_332_synthetic.csv （shape=(412, 52)）\n",
      "\n",
      "正在处理第 351/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_333.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_333_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 352/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_334.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_334_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 353/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_335.csv\n",
      "CSV 文件读取完成，形状为: (378, 52)\n",
      "原始数据长度: 378\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (378, 2), Full synth shape: (378, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_335_synthetic.csv （shape=(378, 52)）\n",
      "\n",
      "正在处理第 354/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_336.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_336_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 355/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_337.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_337_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 356/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_341.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_341_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 357/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_342.csv\n",
      "CSV 文件读取完成，形状为: (288, 52)\n",
      "原始数据长度: 288\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (288, 2), Full synth shape: (288, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_342_synthetic.csv （shape=(288, 52)）\n",
      "\n",
      "正在处理第 358/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_343.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_343_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 359/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_346.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_346_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 360/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_349.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_349_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 361/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_351.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_351_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 362/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_355.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_355_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 363/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_357.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_357_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 364/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_358.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_358_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 365/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_359.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_359_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 366/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_360.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_360_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 367/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_362.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_362_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 368/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_363.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_363_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 369/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_364.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_364_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 370/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_365.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_365_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 371/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_366.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_366_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 372/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_367.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_367_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 373/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_368.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_368_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 374/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_369.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (469, 52)\n",
      "原始数据长度: 469\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (469, 2), Full synth shape: (469, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_369_synthetic.csv （shape=(469, 52)）\n",
      "\n",
      "正在处理第 375/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_210.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_210_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 376/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_212.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_212_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 377/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_213.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_213_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 378/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_217.csv\n",
      "CSV 文件读取完成，形状为: (410, 52)\n",
      "原始数据长度: 410\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (410, 2), Full synth shape: (410, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_217_synthetic.csv （shape=(410, 52)）\n",
      "\n",
      "正在处理第 379/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_218.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_218_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 380/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_219.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_219_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 381/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_220.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_220_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 382/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_221.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_221_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 383/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_224.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_224_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 384/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_226.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_226_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 385/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_227.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_227_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 386/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_228.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_228_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 387/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_229.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_229_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 388/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_230.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_230_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 389/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_231.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_231_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 390/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_783.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_783_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 391/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_785.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_785_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 392/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_786.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_786_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 393/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_794.csv\n",
      "CSV 文件读取完成，形状为: (81, 52)\n",
      "原始数据长度: 81\n",
      "加载训练好的scaler: scaler_segmented.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (81, 2), Full synth shape: (81, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_794_synthetic.csv （shape=(81, 52)）\n",
      "\n",
      "正在处理第 394/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_795.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_795_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 395/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_796.csv\n",
      "CSV 文件读取完成，形状为: (237, 52)\n",
      "原始数据长度: 237\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (237, 2), Full synth shape: (237, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_796_synthetic.csv （shape=(237, 52)）\n",
      "\n",
      "正在处理第 396/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_797.csv\n",
      "CSV 文件读取完成，形状为: (188, 52)\n",
      "原始数据长度: 188\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (188, 2), Full synth shape: (188, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_797_synthetic.csv （shape=(188, 52)）\n",
      "\n",
      "正在处理第 397/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_802.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_802_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 398/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_811.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_811_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 399/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_812.csv\n",
      "CSV 文件读取完成，形状为: (254, 52)\n",
      "原始数据长度: 254\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (254, 2), Full synth shape: (254, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_812_synthetic.csv （shape=(254, 52)）\n",
      "\n",
      "正在处理第 400/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_813.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_813_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 401/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_814.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_814_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 402/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_815.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_815_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 403/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_816.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_816_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 404/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_817.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "加载训练好的scaler: scaler_segmented.pkl\n",
      "加载训练好的模型: transformer_vae_weights.pth\n",
      "对生成的数据进行反归一化...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_817_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "处理完成！成功处理 404/404 个文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taro\\AppData\\Local\\Temp\\ipykernel_2640\\3603144953.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# generate_single_sts.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "INPUT_DIR = r'E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened'\n",
    "\n",
    "INPUT_FILE_PATTERN = r'E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened/**/*.csv'\n",
    "\n",
    "\n",
    "\n",
    "SEQ_LEN   = 300\n",
    "NUM_KPT   = 25\n",
    "INPUT_DIM = NUM_KPT * 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ------------ Positional Encoding ------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, d_model=128, nhead=4, num_layers=2, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len=seq_len)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(d_model * seq_len, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(d_model * seq_len, latent_dim)\n",
    "        \n",
    "        self.fc_latent_to_d_model = nn.Linear(latent_dim, d_model)\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.output_linear = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B, L, D_input)\n",
    "        h = self.input_linear(x)\n",
    "        h_with_pos = self.pos_enc(h)\n",
    "        encoder_output = self.encoder(h_with_pos)\n",
    "        flat_encoder_output = encoder_output.contiguous().view(encoder_output.size(0), -1)\n",
    "        mu = self.fc_mu(flat_encoder_output)\n",
    "        logvar = self.fc_logvar(flat_encoder_output)\n",
    "        return mu, logvar, encoder_output\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, encoder_memory=None):\n",
    "        # z: (B, latent_dim)\n",
    "        if encoder_memory is not None:\n",
    "            initial_tgt_input = self.fc_latent_to_d_model(z).unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "            tgt_with_pos = self.pos_enc(initial_tgt_input)\n",
    "            out = self.decoder(tgt_with_pos, encoder_memory)\n",
    "        else:\n",
    "            x = z.view(z.size(0), self.seq_len, -1) if hasattr(self, 'fc_latent') else self.fc_latent_to_d_model(z).unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "            tgt = self.pos_enc(x)\n",
    "            memory = torch.zeros(self.seq_len, z.size(0), tgt.size(2), device=z.device)\n",
    "            out = self.decoder(tgt.transpose(0,1), memory).transpose(0,1)\n",
    "        return self.output_linear(out)\n",
    "\n",
    "\n",
    "def process_single_file(input_file_path, output_dir, model_path=None, scaler_path=None):\n",
    "    \"\"\"处理单个CSV文件并生成合成数据\"\"\"\n",
    "    try:\n",
    "        print(f\"正在处理文件: {input_file_path}\")\n",
    "        \n",
    "        df = pd.read_csv(input_file_path, header=2, engine='python', on_bad_lines='skip')\n",
    "        print(f\"CSV 文件读取完成，形状为: {df.shape}\")\n",
    "\n",
    "        if df.shape[1] < 2 + INPUT_DIM:\n",
    "            print(f\"警告: 文件 {input_file_path} 的列数不足，跳过处理\")\n",
    "            return False\n",
    "\n",
    "        meta = df.iloc[:, :2].reset_index(drop=True)\n",
    "        data_np = df.iloc[:, 2:2+INPUT_DIM].to_numpy(dtype=np.float32)\n",
    "        orig_len = data_np.shape[0]\n",
    "        print(f\"原始数据长度: {orig_len}\")\n",
    "\n",
    "        if np.isnan(data_np).any():\n",
    "            print(\"检测到NaN值，进行填充...\")\n",
    "            data_np = np.nan_to_num(data_np, nan=0.0)\n",
    "\n",
    "        scaler = None\n",
    "        if scaler_path and os.path.exists(scaler_path):\n",
    "            print(f\"加载训练好的scaler: {scaler_path}\")\n",
    "            import pickle\n",
    "            with open(scaler_path, 'rb') as f:\n",
    "                scaler = pickle.load(f)\n",
    "            data_np_normalized = scaler.transform(data_np)\n",
    "        else:\n",
    "            print(\"未找到scaler文件，使用原始数据（可能导致结果不准确）\")\n",
    "            data_np_normalized = data_np\n",
    "\n",
    "        if orig_len < SEQ_LEN:\n",
    "            pad = np.zeros((SEQ_LEN - orig_len, INPUT_DIM), dtype=np.float32)\n",
    "            data_for_model = np.vstack([data_np_normalized, pad])\n",
    "        else:\n",
    "            data_for_model = data_np_normalized[:SEQ_LEN]\n",
    "\n",
    "        model = TransformerVAE(INPUT_DIM, SEQ_LEN).to(DEVICE)\n",
    "        \n",
    "        if model_path and os.path.exists(model_path):\n",
    "            print(f\"加载训练好的模型: {model_path}\")\n",
    "            model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "            model.eval()\n",
    "        else:\n",
    "            print(\"警告：未找到训练好的模型，使用随机初始化的模型（结果将是随机的）\")\n",
    "            model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(data_for_model[None]).to(DEVICE)\n",
    "            if hasattr(model, 'encode') and len(model.encode(x)) == 3:\n",
    "                mu, logvar, encoder_output = model.encode(x)\n",
    "                z = model.reparameterize(mu, logvar)\n",
    "                synth = model.decode(z, encoder_output)[0].cpu().numpy()\n",
    "            else:\n",
    "                mu, logvar = model.encode(x)\n",
    "                z = model.reparameterize(mu, logvar)\n",
    "                synth = model.decode(z)[0].cpu().numpy()\n",
    "\n",
    "        if scaler is not None:\n",
    "            print(\"对生成的数据进行反归一化...\")\n",
    "            synth_for_inverse = synth[:orig_len] if orig_len < SEQ_LEN else synth\n",
    "            synth_denormalized = scaler.inverse_transform(synth_for_inverse)\n",
    "            \n",
    "            if orig_len < SEQ_LEN:\n",
    "                pad_back = np.zeros((SEQ_LEN - orig_len, INPUT_DIM), dtype=np.float32)\n",
    "                synth = np.vstack([synth_denormalized, pad_back])\n",
    "            else:\n",
    "                synth = synth_denormalized\n",
    "        else:\n",
    "            print(\"跳过反归一化步骤\")\n",
    "\n",
    "        if orig_len > SEQ_LEN:\n",
    "            pad_back = np.zeros((orig_len - SEQ_LEN, INPUT_DIM), dtype=np.float32)\n",
    "            full_synth = np.vstack([synth, pad_back])\n",
    "        else:\n",
    "            full_synth = synth[:orig_len]\n",
    "\n",
    "        print(f\"Meta shape: {meta.shape}, Full synth shape: {full_synth.shape}\")\n",
    "        \n",
    "        if meta.shape[0] != full_synth.shape[0]:\n",
    "            if meta.shape[0] > full_synth.shape[0]:\n",
    "                pad_back = np.zeros((meta.shape[0] - full_synth.shape[0], INPUT_DIM), dtype=np.float32)\n",
    "                full_synth = np.vstack([full_synth, pad_back])\n",
    "            else:\n",
    "                full_synth = full_synth[:meta.shape[0]]\n",
    "\n",
    "        out_arr = np.hstack([meta.values, full_synth])\n",
    "        out_cols = list(meta.columns) + list(df.columns[2:2+INPUT_DIM])\n",
    "        out_df = pd.DataFrame(out_arr, columns=out_cols)\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        input_filename = os.path.basename(input_file_path)\n",
    "        base_name, ext = os.path.splitext(input_filename)\n",
    "        output_filename = f\"{base_name}_synthetic{ext}\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        out_df.to_csv(output_path, header=False, index=False, float_format='%.6f')\n",
    "        print(f\"✔ 合成结果已保存：{output_path} （shape={out_df.shape}）\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 处理文件 {input_file_path} 时出错: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"开始批量处理CSV文件...\")\n",
    "    \n",
    "    all_input_files = glob.glob(INPUT_FILE_PATTERN, recursive=True)\n",
    "    \n",
    "    if not all_input_files:\n",
    "        print(f\"没有找到匹配模式 '{INPUT_FILE_PATTERN}' 的文件。请检查路径和模式是否正确。\")\n",
    "        \n",
    "        direct_pattern = os.path.join(INPUT_DIR, \"*.csv\")\n",
    "        all_input_files = glob.glob(direct_pattern)\n",
    "        \n",
    "        if not all_input_files:\n",
    "            print(f\"也没有在 '{INPUT_DIR}' 中找到CSV文件。\")\n",
    "            print(\"请检查以下几点：\")\n",
    "            print(\"1. 路径是否正确\")\n",
    "            print(\"2. 文件夹中是否包含CSV文件\")\n",
    "            print(\"3. 是否有足够的文件访问权限\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"在主目录中找到 {len(all_input_files)} 个CSV文件\")\n",
    "    else:\n",
    "        print(f\"找到 {len(all_input_files)} 个匹配文件\")\n",
    "    \n",
    "    success_count = 0\n",
    "    for i, file_path in enumerate(all_input_files):\n",
    "        print(f\"\\n正在处理第 {i+1}/{len(all_input_files)} 个文件...\")\n",
    "        if process_single_file(file_path, OUTPUT_DIR, MODEL_PATH, SCALER_PATH):\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\n处理完成！成功处理 {success_count}/{len(all_input_files)} 个文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00de660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "开始批量处理CSV文件...\n",
      "找到 404 个匹配文件\n",
      "\n",
      "正在处理第 1/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_301.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_301_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 2/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_301_synthetic.csv\n",
      "CSV 文件读取完成，形状为: (505, 52)\n",
      "原始数据长度: 505\n",
      "初始化模型...\n",
      "Meta shape: (505, 2), Full synth shape: (505, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_301_synthetic_synthetic.csv （shape=(505, 52)）\n",
      "\n",
      "正在处理第 3/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_305.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_305_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 4/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_306.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_306_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 5/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_307.csv\n",
      "CSV 文件读取完成，形状为: (101, 52)\n",
      "原始数据长度: 101\n",
      "初始化模型...\n",
      "Meta shape: (101, 2), Full synth shape: (101, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_307_synthetic.csv （shape=(101, 52)）\n",
      "\n",
      "正在处理第 6/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_316.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_316_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 7/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_317.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_317_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 8/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_318.csv\n",
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "初始化模型...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_318_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 9/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_319.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_319_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 10/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_320.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_320_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 11/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_321.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_321_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 12/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_322.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_322_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 13/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_323.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_323_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 14/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_325.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_325_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 15/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_327.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_327_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 16/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt204_C_n_328.csv\n",
      "CSV 文件读取完成，形状为: (89, 52)\n",
      "原始数据长度: 89\n",
      "初始化模型...\n",
      "Meta shape: (89, 2), Full synth shape: (89, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt204_C_n_328_synthetic.csv （shape=(89, 52)）\n",
      "\n",
      "正在处理第 17/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_33.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_33_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 18/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_34.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_34_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 19/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_35.csv\n",
      "CSV 文件读取完成，形状为: (417, 52)\n",
      "原始数据长度: 417\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (417, 2), Full synth shape: (417, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_35_synthetic.csv （shape=(417, 52)）\n",
      "\n",
      "正在处理第 20/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_36.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_36_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 21/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_37.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_37_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 22/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_39.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_39_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 23/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_44.csv\n",
      "CSV 文件读取完成，形状为: (287, 52)\n",
      "原始数据长度: 287\n",
      "初始化模型...\n",
      "Meta shape: (287, 2), Full synth shape: (287, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_44_synthetic.csv （shape=(287, 52)）\n",
      "\n",
      "正在处理第 24/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt227_C_n_45.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt227_C_n_45_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 25/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_375.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_375_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 26/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_376.csv\n",
      "CSV 文件读取完成，形状为: (328, 52)\n",
      "原始数据长度: 328\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (328, 2), Full synth shape: (328, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_376_synthetic.csv （shape=(328, 52)）\n",
      "\n",
      "正在处理第 27/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_379.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_379_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 28/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_380.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_380_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 29/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_386.csv\n",
      "CSV 文件读取完成，形状为: (219, 52)\n",
      "原始数据长度: 219\n",
      "初始化模型...\n",
      "Meta shape: (219, 2), Full synth shape: (219, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_386_synthetic.csv （shape=(219, 52)）\n",
      "\n",
      "正在处理第 30/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_387.csv\n",
      "CSV 文件读取完成，形状为: (158, 52)\n",
      "原始数据长度: 158\n",
      "初始化模型...\n",
      "Meta shape: (158, 2), Full synth shape: (158, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_387_synthetic.csv （shape=(158, 52)）\n",
      "\n",
      "正在处理第 31/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_389.csv\n",
      "CSV 文件读取完成，形状为: (355, 52)\n",
      "原始数据长度: 355\n",
      "初始化模型...\n",
      "Meta shape: (355, 2), Full synth shape: (355, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_389_synthetic.csv （shape=(355, 52)）\n",
      "\n",
      "正在处理第 32/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_390.csv\n",
      "CSV 文件读取完成，形状为: (412, 52)\n",
      "原始数据长度: 412\n",
      "初始化模型...\n",
      "Meta shape: (412, 2), Full synth shape: (412, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_390_synthetic.csv （shape=(412, 52)）\n",
      "\n",
      "正在处理第 33/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_392.csv\n",
      "CSV 文件读取完成，形状为: (52, 52)\n",
      "原始数据长度: 52\n",
      "初始化模型...\n",
      "Meta shape: (52, 2), Full synth shape: (52, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_392_synthetic.csv （shape=(52, 52)）\n",
      "\n",
      "正在处理第 34/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_398.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_398_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 35/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_399.csv\n",
      "CSV 文件读取完成，形状为: (250, 52)\n",
      "原始数据长度: 250\n",
      "初始化模型...\n",
      "Meta shape: (250, 2), Full synth shape: (250, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_399_synthetic.csv （shape=(250, 52)）\n",
      "\n",
      "正在处理第 36/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_400.csv\n",
      "CSV 文件读取完成，形状为: (148, 52)\n",
      "原始数据长度: 148\n",
      "初始化模型...\n",
      "Meta shape: (148, 2), Full synth shape: (148, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_400_synthetic.csv （shape=(148, 52)）\n",
      "\n",
      "正在处理第 37/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_401.csv\n",
      "CSV 文件读取完成，形状为: (239, 52)\n",
      "原始数据长度: 239\n",
      "初始化模型...\n",
      "Meta shape: (239, 2), Full synth shape: (239, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_401_synthetic.csv （shape=(239, 52)）\n",
      "\n",
      "正在处理第 38/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_403.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_403_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 39/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_404.csv\n",
      "CSV 文件读取完成，形状为: (72, 52)\n",
      "原始数据长度: 72\n",
      "初始化模型...\n",
      "Meta shape: (72, 2), Full synth shape: (72, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_404_synthetic.csv （shape=(72, 52)）\n",
      "\n",
      "正在处理第 40/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_405.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_405_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 41/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_406.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_406_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 42/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_407.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_407_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 43/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_416.csv\n",
      "CSV 文件读取完成，形状为: (185, 52)\n",
      "原始数据长度: 185\n",
      "初始化模型...\n",
      "Meta shape: (185, 2), Full synth shape: (185, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_416_synthetic.csv （shape=(185, 52)）\n",
      "\n",
      "正在处理第 44/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_417.csv\n",
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "初始化模型...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_417_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 45/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_418.csv\n",
      "CSV 文件读取完成，形状为: (371, 52)\n",
      "原始数据长度: 371\n",
      "初始化模型...\n",
      "Meta shape: (371, 2), Full synth shape: (371, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_418_synthetic.csv （shape=(371, 52)）\n",
      "\n",
      "正在处理第 46/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_420.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_420_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 47/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_421.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_421_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 48/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_422.csv\n",
      "CSV 文件读取完成，形状为: (132, 52)\n",
      "原始数据长度: 132\n",
      "初始化模型...\n",
      "Meta shape: (132, 2), Full synth shape: (132, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_422_synthetic.csv （shape=(132, 52)）\n",
      "\n",
      "正在处理第 49/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_424.csv\n",
      "CSV 文件读取完成，形状为: (163, 52)\n",
      "原始数据长度: 163\n",
      "初始化模型...\n",
      "Meta shape: (163, 2), Full synth shape: (163, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_424_synthetic.csv （shape=(163, 52)）\n",
      "\n",
      "正在处理第 50/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_426.csv\n",
      "CSV 文件读取完成，形状为: (155, 52)\n",
      "原始数据长度: 155\n",
      "初始化模型...\n",
      "Meta shape: (155, 2), Full synth shape: (155, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_426_synthetic.csv （shape=(155, 52)）\n",
      "\n",
      "正在处理第 51/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_428.csv\n",
      "CSV 文件读取完成，形状为: (184, 52)\n",
      "原始数据长度: 184\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (184, 2), Full synth shape: (184, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_428_synthetic.csv （shape=(184, 52)）\n",
      "\n",
      "正在处理第 52/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_429.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_429_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 53/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_430.csv\n",
      "CSV 文件读取完成，形状为: (244, 52)\n",
      "原始数据长度: 244\n",
      "初始化模型...\n",
      "Meta shape: (244, 2), Full synth shape: (244, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_430_synthetic.csv （shape=(244, 52)）\n",
      "\n",
      "正在处理第 54/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt230_C_n_434.csv\n",
      "CSV 文件读取完成，形状为: (372, 52)\n",
      "原始数据长度: 372\n",
      "初始化模型...\n",
      "Meta shape: (372, 2), Full synth shape: (372, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt230_C_n_434_synthetic.csv （shape=(372, 52)）\n",
      "\n",
      "正在处理第 55/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_698.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_698_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 56/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_699.csv\n",
      "CSV 文件读取完成，形状为: (398, 52)\n",
      "原始数据长度: 398\n",
      "初始化模型...\n",
      "Meta shape: (398, 2), Full synth shape: (398, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_699_synthetic.csv （shape=(398, 52)）\n",
      "\n",
      "正在处理第 57/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_700.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_700_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 58/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_701.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_701_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 59/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_702.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_702_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 60/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_703.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_703_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 61/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_705.csv\n",
      "CSV 文件读取完成，形状为: (152, 52)\n",
      "原始数据长度: 152\n",
      "初始化模型...\n",
      "Meta shape: (152, 2), Full synth shape: (152, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_705_synthetic.csv （shape=(152, 52)）\n",
      "\n",
      "正在处理第 62/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_709.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_709_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 63/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_712.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_712_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 64/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_717.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_717_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 65/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_718.csv\n",
      "CSV 文件读取完成，形状为: (414, 52)\n",
      "原始数据长度: 414\n",
      "初始化模型...\n",
      "Meta shape: (414, 2), Full synth shape: (414, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_718_synthetic.csv （shape=(414, 52)）\n",
      "\n",
      "正在处理第 66/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_719.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_719_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 67/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_720.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_720_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 68/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_721.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_721_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 69/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_722.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_722_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 70/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_723.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_723_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 71/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_724.csv\n",
      "CSV 文件读取完成，形状为: (257, 52)\n",
      "原始数据长度: 257\n",
      "初始化模型...\n",
      "Meta shape: (257, 2), Full synth shape: (257, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_724_synthetic.csv （shape=(257, 52)）\n",
      "\n",
      "正在处理第 72/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_725.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_725_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 73/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt253_PD_n_726.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt253_PD_n_726_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 74/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_101.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_101_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 75/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_50.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_50_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 76/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_51.csv\n",
      "CSV 文件读取完成，形状为: (234, 52)\n",
      "原始数据长度: 234\n",
      "初始化模型...\n",
      "Meta shape: (234, 2), Full synth shape: (234, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_51_synthetic.csv （shape=(234, 52)）\n",
      "\n",
      "正在处理第 77/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_52.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_52_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 78/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_53.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_53_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 79/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_54.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_54_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 80/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_55.csv\n",
      "CSV 文件读取完成，形状为: (170, 52)\n",
      "原始数据长度: 170\n",
      "初始化模型...\n",
      "Meta shape: (170, 2), Full synth shape: (170, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_55_synthetic.csv （shape=(170, 52)）\n",
      "\n",
      "正在处理第 81/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_56.csv\n",
      "CSV 文件读取完成，形状为: (271, 52)\n",
      "原始数据长度: 271\n",
      "初始化模型...\n",
      "Meta shape: (271, 2), Full synth shape: (271, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_56_synthetic.csv （shape=(271, 52)）\n",
      "\n",
      "正在处理第 82/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_57.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_57_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 83/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_62.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_62_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 84/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_63.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_63_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 85/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_64.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_64_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 86/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_71.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_71_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 87/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_73.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_73_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 88/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_75.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_75_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 89/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_76.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_76_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 90/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_77.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_77_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 91/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_78.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_78_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 92/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_79.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_79_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 93/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_80.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_80_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 94/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_81.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_81_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 95/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_86.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_86_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 96/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_87.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_87_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 97/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_89.csv\n",
      "CSV 文件读取完成，形状为: (320, 52)\n",
      "原始数据长度: 320\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (320, 2), Full synth shape: (320, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_89_synthetic.csv （shape=(320, 52)）\n",
      "\n",
      "正在处理第 98/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_90.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_90_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 99/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt275_PD_n_91.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt275_PD_n_91_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 100/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_438.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_438_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 101/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_439.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_439_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 102/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_440.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_440_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 103/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_441.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_441_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 104/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_447.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_447_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 105/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_451.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_451_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 106/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_452.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_452_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 107/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_454.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_454_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 108/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_455.csv\n",
      "CSV 文件读取完成，形状为: (142, 52)\n",
      "原始数据长度: 142\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (142, 2), Full synth shape: (142, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_455_synthetic.csv （shape=(142, 52)）\n",
      "\n",
      "正在处理第 109/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_459.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_459_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 110/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_460.csv\n",
      "CSV 文件读取完成，形状为: (148, 52)\n",
      "原始数据长度: 148\n",
      "初始化模型...\n",
      "Meta shape: (148, 2), Full synth shape: (148, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_460_synthetic.csv （shape=(148, 52)）\n",
      "\n",
      "正在处理第 111/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_461.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_461_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 112/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_462.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_462_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 113/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt324_PD_n_463.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt324_PD_n_463_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 114/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_102.csv\n",
      "CSV 文件读取完成，形状为: (295, 52)\n",
      "原始数据长度: 295\n",
      "初始化模型...\n",
      "Meta shape: (295, 2), Full synth shape: (295, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_102_synthetic.csv （shape=(295, 52)）\n",
      "\n",
      "正在处理第 115/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_103.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_103_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 116/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_104.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_104_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 117/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_105.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_105_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 118/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_108.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_108_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 119/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_109.csv\n",
      "CSV 文件读取完成，形状为: (88, 52)\n",
      "原始数据长度: 88\n",
      "初始化模型...\n",
      "Meta shape: (88, 2), Full synth shape: (88, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_109_synthetic.csv （shape=(88, 52)）\n",
      "\n",
      "正在处理第 120/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_111.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_111_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 121/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_112.csv\n",
      "CSV 文件读取完成，形状为: (140, 52)\n",
      "原始数据长度: 140\n",
      "初始化模型...\n",
      "Meta shape: (140, 2), Full synth shape: (140, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_112_synthetic.csv （shape=(140, 52)）\n",
      "\n",
      "正在处理第 122/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_115.csv\n",
      "CSV 文件读取完成，形状为: (426, 52)\n",
      "原始数据长度: 426\n",
      "初始化模型...\n",
      "Meta shape: (426, 2), Full synth shape: (426, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_115_synthetic.csv （shape=(426, 52)）\n",
      "\n",
      "正在处理第 123/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_117.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_117_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 124/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_118.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_118_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 125/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt325_C_n_119.csv\n",
      "CSV 文件读取完成，形状为: (24, 52)\n",
      "原始数据长度: 24\n",
      "初始化模型...\n",
      "Meta shape: (24, 2), Full synth shape: (24, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt325_C_n_119_synthetic.csv （shape=(24, 52)）\n",
      "\n",
      "正在处理第 126/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_754.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_754_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 127/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_756.csv\n",
      "CSV 文件读取完成，形状为: (125, 52)\n",
      "原始数据长度: 125\n",
      "初始化模型...\n",
      "Meta shape: (125, 2), Full synth shape: (125, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_756_synthetic.csv （shape=(125, 52)）\n",
      "\n",
      "正在处理第 128/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_759.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_759_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 129/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_762.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_762_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 130/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_763.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_763_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 131/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_764.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_764_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 132/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_765.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_765_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 133/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_766.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_766_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 134/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_767.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_767_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 135/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_770.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_770_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 136/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_771.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_771_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 137/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_772.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_772_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 138/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_773.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_773_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 139/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_774.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_774_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 140/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_777.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_777_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 141/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_778.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_778_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 142/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_779.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_779_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 143/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt384_PD_n_780.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt384_PD_n_780_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 144/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_267.csv\n",
      "CSV 文件读取完成，形状为: (324, 52)\n",
      "原始数据长度: 324\n",
      "初始化模型...\n",
      "Meta shape: (324, 2), Full synth shape: (324, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_267_synthetic.csv （shape=(324, 52)）\n",
      "\n",
      "正在处理第 145/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_268.csv\n",
      "CSV 文件读取完成，形状为: (175, 52)\n",
      "原始数据长度: 175\n",
      "初始化模型...\n",
      "Meta shape: (175, 2), Full synth shape: (175, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_268_synthetic.csv （shape=(175, 52)）\n",
      "\n",
      "正在处理第 146/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_270.csv\n",
      "CSV 文件读取完成，形状为: (86, 52)\n",
      "原始数据长度: 86\n",
      "初始化模型...\n",
      "Meta shape: (86, 2), Full synth shape: (86, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_270_synthetic.csv （shape=(86, 52)）\n",
      "\n",
      "正在处理第 147/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_272.csv\n",
      "CSV 文件读取完成，形状为: (309, 52)\n",
      "原始数据长度: 309\n",
      "初始化模型...\n",
      "Meta shape: (309, 2), Full synth shape: (309, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_272_synthetic.csv （shape=(309, 52)）\n",
      "\n",
      "正在处理第 148/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_274.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_274_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 149/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_275.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_275_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 150/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_276.csv\n",
      "CSV 文件读取完成，形状为: (230, 52)\n",
      "原始数据长度: 230\n",
      "初始化模型...\n",
      "Meta shape: (230, 2), Full synth shape: (230, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_276_synthetic.csv （shape=(230, 52)）\n",
      "\n",
      "正在处理第 151/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_278.csv\n",
      "CSV 文件读取完成，形状为: (347, 52)\n",
      "原始数据长度: 347\n",
      "初始化模型...\n",
      "Meta shape: (347, 2), Full synth shape: (347, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_278_synthetic.csv （shape=(347, 52)）\n",
      "\n",
      "正在处理第 152/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_279.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_279_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 153/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_280.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_280_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 154/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_281.csv\n",
      "CSV 文件读取完成，形状为: (474, 52)\n",
      "原始数据长度: 474\n",
      "初始化模型...\n",
      "Meta shape: (474, 2), Full synth shape: (474, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_281_synthetic.csv （shape=(474, 52)）\n",
      "\n",
      "正在处理第 155/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_283.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_283_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 156/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_284.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_284_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 157/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_285.csv\n",
      "CSV 文件读取完成，形状为: (316, 52)\n",
      "原始数据长度: 316\n",
      "初始化模型...\n",
      "Meta shape: (316, 2), Full synth shape: (316, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_285_synthetic.csv （shape=(316, 52)）\n",
      "\n",
      "正在处理第 158/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_286.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_286_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 159/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_287.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_287_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 160/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_290.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_290_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 161/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_293.csv\n",
      "CSV 文件读取完成，形状为: (488, 52)\n",
      "原始数据长度: 488\n",
      "初始化模型...\n",
      "Meta shape: (488, 2), Full synth shape: (488, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_293_synthetic.csv （shape=(488, 52)）\n",
      "\n",
      "正在处理第 162/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_295.csv\n",
      "CSV 文件读取完成，形状为: (499, 52)\n",
      "原始数据长度: 499\n",
      "初始化模型...\n",
      "Meta shape: (499, 2), Full synth shape: (499, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_295_synthetic.csv （shape=(499, 52)）\n",
      "\n",
      "正在处理第 163/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_296.csv\n",
      "CSV 文件读取完成，形状为: (419, 52)\n",
      "原始数据长度: 419\n",
      "初始化模型...\n",
      "Meta shape: (419, 2), Full synth shape: (419, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_296_synthetic.csv （shape=(419, 52)）\n",
      "\n",
      "正在处理第 164/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt396_PD_n_299.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt396_PD_n_299_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 165/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_633.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_633_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 166/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_634.csv\n",
      "CSV 文件读取完成，形状为: (413, 52)\n",
      "原始数据长度: 413\n",
      "初始化模型...\n",
      "Meta shape: (413, 2), Full synth shape: (413, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_634_synthetic.csv （shape=(413, 52)）\n",
      "\n",
      "正在处理第 167/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_636.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_636_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 168/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_645.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_645_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 169/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_646.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_646_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 170/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_647.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_647_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 171/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_648.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_648_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 172/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_649.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_649_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 173/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_650.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_650_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 174/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_651.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_651_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 175/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt398_PD_n_653.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt398_PD_n_653_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 176/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_464.csv\n",
      "CSV 文件读取完成，形状为: (213, 52)\n",
      "原始数据长度: 213\n",
      "初始化模型...\n",
      "Meta shape: (213, 2), Full synth shape: (213, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_464_synthetic.csv （shape=(213, 52)）\n",
      "\n",
      "正在处理第 177/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_465.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_465_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 178/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_473.csv\n",
      "CSV 文件读取完成，形状为: (109, 52)\n",
      "原始数据长度: 109\n",
      "初始化模型...\n",
      "Meta shape: (109, 2), Full synth shape: (109, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_473_synthetic.csv （shape=(109, 52)）\n",
      "\n",
      "正在处理第 179/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_474.csv\n",
      "CSV 文件读取完成，形状为: (167, 52)\n",
      "原始数据长度: 167\n",
      "初始化模型...\n",
      "Meta shape: (167, 2), Full synth shape: (167, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_474_synthetic.csv （shape=(167, 52)）\n",
      "\n",
      "正在处理第 180/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_475.csv\n",
      "CSV 文件读取完成，形状为: (226, 52)\n",
      "原始数据长度: 226\n",
      "初始化模型...\n",
      "Meta shape: (226, 2), Full synth shape: (226, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_475_synthetic.csv （shape=(226, 52)）\n",
      "\n",
      "正在处理第 181/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_476.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_476_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 182/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_477.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (264, 52)\n",
      "原始数据长度: 264\n",
      "初始化模型...\n",
      "Meta shape: (264, 2), Full synth shape: (264, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_477_synthetic.csv （shape=(264, 52)）\n",
      "\n",
      "正在处理第 183/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_479.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_479_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 184/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_480.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_480_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 185/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_481.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_481_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 186/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt400_C_n_482.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt400_C_n_482_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 187/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_121.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_121_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 188/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_122.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_122_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 189/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_125.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_125_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 190/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_126.csv\n",
      "CSV 文件读取完成，形状为: (198, 52)\n",
      "原始数据长度: 198\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (198, 2), Full synth shape: (198, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_126_synthetic.csv （shape=(198, 52)）\n",
      "\n",
      "正在处理第 191/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_127.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_127_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 192/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_128.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_128_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 193/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_143.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_143_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 194/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_157.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_157_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 195/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_158.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_158_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 196/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_159.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_159_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 197/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_160.csv\n",
      "CSV 文件读取完成，形状为: (430, 52)\n",
      "原始数据长度: 430\n",
      "初始化模型...\n",
      "Meta shape: (430, 2), Full synth shape: (430, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_160_synthetic.csv （shape=(430, 52)）\n",
      "\n",
      "正在处理第 198/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_161.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_161_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 199/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt405_C_n_162.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt405_C_n_162_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 200/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_174.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_174_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 201/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_178.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_178_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 202/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_179.csv\n",
      "CSV 文件读取完成，形状为: (176, 52)\n",
      "原始数据长度: 176\n",
      "初始化模型...\n",
      "Meta shape: (176, 2), Full synth shape: (176, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_179_synthetic.csv （shape=(176, 52)）\n",
      "\n",
      "正在处理第 203/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_180.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_180_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 204/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_181.csv\n",
      "CSV 文件读取完成，形状为: (252, 52)\n",
      "原始数据长度: 252\n",
      "初始化模型...\n",
      "Meta shape: (252, 2), Full synth shape: (252, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_181_synthetic.csv （shape=(252, 52)）\n",
      "\n",
      "正在处理第 205/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_182.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_182_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 206/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_184.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_184_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 207/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_187.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_187_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 208/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_188.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_188_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 209/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_189.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_189_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 210/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_190.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_190_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 211/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_192.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_192_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 212/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_198.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_198_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 213/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_199.csv\n",
      "CSV 文件读取完成，形状为: (504, 52)\n",
      "原始数据长度: 504\n",
      "初始化模型...\n",
      "Meta shape: (504, 2), Full synth shape: (504, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_199_synthetic.csv （shape=(504, 52)）\n",
      "\n",
      "正在处理第 214/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_200.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_200_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 215/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_201.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_201_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 216/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_203.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_203_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 217/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_204.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_204_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 218/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_205.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_205_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 219/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt412_PD_n_206.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt412_PD_n_206_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 220/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_728.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_728_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 221/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_729.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_729_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 222/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_730.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_730_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 223/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_731.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_731_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 224/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_732.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_732_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 225/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_736.csv\n",
      "CSV 文件读取完成，形状为: (194, 52)\n",
      "原始数据长度: 194\n",
      "初始化模型...\n",
      "Meta shape: (194, 2), Full synth shape: (194, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_736_synthetic.csv （shape=(194, 52)）\n",
      "\n",
      "正在处理第 226/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_737.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_737_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 227/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt416_C_n_751.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt416_C_n_751_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 228/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_486.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_486_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 229/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_487.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_487_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 230/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_488.csv\n",
      "CSV 文件读取完成，形状为: (403, 52)\n",
      "原始数据长度: 403\n",
      "初始化模型...\n",
      "Meta shape: (403, 2), Full synth shape: (403, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_488_synthetic.csv （shape=(403, 52)）\n",
      "\n",
      "正在处理第 231/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_489.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_489_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 232/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_490.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_490_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 233/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_491.csv\n",
      "CSV 文件读取完成，形状为: (108, 52)\n",
      "原始数据长度: 108\n",
      "初始化模型...\n",
      "Meta shape: (108, 2), Full synth shape: (108, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_491_synthetic.csv （shape=(108, 52)）\n",
      "\n",
      "正在处理第 234/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_493.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_493_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 235/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_495.csv\n",
      "CSV 文件读取完成，形状为: (59, 52)\n",
      "原始数据长度: 59\n",
      "初始化模型...\n",
      "Meta shape: (59, 2), Full synth shape: (59, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_495_synthetic.csv （shape=(59, 52)）\n",
      "\n",
      "正在处理第 236/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_497.csv\n",
      "CSV 文件读取完成，形状为: (107, 52)\n",
      "原始数据长度: 107\n",
      "初始化模型...\n",
      "Meta shape: (107, 2), Full synth shape: (107, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_497_synthetic.csv （shape=(107, 52)）\n",
      "\n",
      "正在处理第 237/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_499.csv\n",
      "CSV 文件读取完成，形状为: (120, 52)\n",
      "原始数据长度: 120\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (120, 2), Full synth shape: (120, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_499_synthetic.csv （shape=(120, 52)）\n",
      "\n",
      "正在处理第 238/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_501.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_501_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 239/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_502.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_502_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 240/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_503.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_503_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 241/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_504.csv\n",
      "CSV 文件读取完成，形状为: (462, 52)\n",
      "原始数据长度: 462\n",
      "初始化模型...\n",
      "Meta shape: (462, 2), Full synth shape: (462, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_504_synthetic.csv （shape=(462, 52)）\n",
      "\n",
      "正在处理第 242/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_508.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_508_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 243/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_509.csv\n",
      "CSV 文件读取完成，形状为: (491, 52)\n",
      "原始数据长度: 491\n",
      "初始化模型...\n",
      "Meta shape: (491, 2), Full synth shape: (491, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_509_synthetic.csv （shape=(491, 52)）\n",
      "\n",
      "正在处理第 244/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt467_PD_n_510.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt467_PD_n_510_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 245/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_661.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_661_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 246/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_662.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_662_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 247/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_663.csv\n",
      "CSV 文件读取完成，形状为: (449, 52)\n",
      "原始数据长度: 449\n",
      "初始化模型...\n",
      "Meta shape: (449, 2), Full synth shape: (449, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_663_synthetic.csv （shape=(449, 52)）\n",
      "\n",
      "正在处理第 248/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_664.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_664_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 249/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_665.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_665_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 250/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_675.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_675_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 251/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_676.csv\n",
      "CSV 文件读取完成，形状为: (347, 52)\n",
      "原始数据长度: 347\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (347, 2), Full synth shape: (347, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_676_synthetic.csv （shape=(347, 52)）\n",
      "\n",
      "正在处理第 252/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_677.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_677_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 253/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt495_C_n_678.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt495_C_n_678_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 254/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_1.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_1_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 255/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_12.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_12_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 256/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_15_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 257/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_17.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_17_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 258/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_19.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_19_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 259/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_2.csv\n",
      "CSV 文件读取完成，形状为: (401, 52)\n",
      "原始数据长度: 401\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (401, 2), Full synth shape: (401, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_2_synthetic.csv （shape=(401, 52)）\n",
      "\n",
      "正在处理第 260/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_20.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_20_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 261/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_22.csv\n",
      "CSV 文件读取完成，形状为: (425, 52)\n",
      "原始数据长度: 425\n",
      "初始化模型...\n",
      "Meta shape: (425, 2), Full synth shape: (425, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_22_synthetic.csv （shape=(425, 52)）\n",
      "\n",
      "正在处理第 262/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_24.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_24_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 263/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_26.csv\n",
      "CSV 文件读取完成，形状为: (136, 52)\n",
      "原始数据长度: 136\n",
      "初始化模型...\n",
      "Meta shape: (136, 2), Full synth shape: (136, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_26_synthetic.csv （shape=(136, 52)）\n",
      "\n",
      "正在处理第 264/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_27.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_27_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 265/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_28.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_28_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 266/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_29.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (394, 52)\n",
      "原始数据长度: 394\n",
      "初始化模型...\n",
      "Meta shape: (394, 2), Full synth shape: (394, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_29_synthetic.csv （shape=(394, 52)）\n",
      "\n",
      "正在处理第 267/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_3.csv\n",
      "CSV 文件读取完成，形状为: (384, 52)\n",
      "原始数据长度: 384\n",
      "初始化模型...\n",
      "Meta shape: (384, 2), Full synth shape: (384, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_3_synthetic.csv （shape=(384, 52)）\n",
      "\n",
      "正在处理第 268/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_30.csv\n",
      "CSV 文件读取完成，形状为: (440, 52)\n",
      "原始数据长度: 440\n",
      "初始化模型...\n",
      "Meta shape: (440, 2), Full synth shape: (440, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_30_synthetic.csv （shape=(440, 52)）\n",
      "\n",
      "正在处理第 269/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_31.csv\n",
      "CSV 文件读取完成，形状为: (100, 52)\n",
      "原始数据长度: 100\n",
      "初始化模型...\n",
      "Meta shape: (100, 2), Full synth shape: (100, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_31_synthetic.csv （shape=(100, 52)）\n",
      "\n",
      "正在处理第 270/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_32.csv\n",
      "CSV 文件读取完成，形状为: (97, 52)\n",
      "原始数据长度: 97\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (97, 2), Full synth shape: (97, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_32_synthetic.csv （shape=(97, 52)）\n",
      "\n",
      "正在处理第 271/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_4.csv\n",
      "CSV 文件读取完成，形状为: (425, 52)\n",
      "原始数据长度: 425\n",
      "初始化模型...\n",
      "Meta shape: (425, 2), Full synth shape: (425, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_4_synthetic.csv （shape=(425, 52)）\n",
      "\n",
      "正在处理第 272/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_5.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_5_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 273/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_6.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_6_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 274/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt596_PD_n_8.csv\n",
      "CSV 文件读取完成，形状为: (262, 52)\n",
      "原始数据长度: 262\n",
      "初始化模型...\n",
      "Meta shape: (262, 2), Full synth shape: (262, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt596_PD_n_8_synthetic.csv （shape=(262, 52)）\n",
      "\n",
      "正在处理第 275/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_234.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_234_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 276/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_235.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_235_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 277/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_237.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_237_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 278/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_238.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_238_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 279/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_239.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_239_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 280/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_242.csv\n",
      "CSV 文件读取完成，形状为: (165, 52)\n",
      "原始数据长度: 165\n",
      "初始化模型...\n",
      "Meta shape: (165, 2), Full synth shape: (165, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_242_synthetic.csv （shape=(165, 52)）\n",
      "\n",
      "正在处理第 281/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_248.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_248_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 282/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_250.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_250_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 283/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_252.csv\n",
      "CSV 文件读取完成，形状为: (353, 52)\n",
      "原始数据长度: 353\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (353, 2), Full synth shape: (353, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_252_synthetic.csv （shape=(353, 52)）\n",
      "\n",
      "正在处理第 284/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_256.csv\n",
      "CSV 文件读取完成，形状为: (210, 52)\n",
      "原始数据长度: 210\n",
      "初始化模型...\n",
      "Meta shape: (210, 2), Full synth shape: (210, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_256_synthetic.csv （shape=(210, 52)）\n",
      "\n",
      "正在处理第 285/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_258.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_258_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 286/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt631_PD_n_263.csv\n",
      "CSV 文件读取完成，形状为: (374, 52)\n",
      "原始数据长度: 374\n",
      "初始化模型...\n",
      "Meta shape: (374, 2), Full synth shape: (374, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt631_PD_n_263_synthetic.csv （shape=(374, 52)）\n",
      "\n",
      "正在处理第 287/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_513.csv\n",
      "CSV 文件读取完成，形状为: (498, 52)\n",
      "原始数据长度: 498\n",
      "初始化模型...\n",
      "Meta shape: (498, 2), Full synth shape: (498, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_513_synthetic.csv （shape=(498, 52)）\n",
      "\n",
      "正在处理第 288/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_514.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_514_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 289/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_515.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_515_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 290/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_516.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_516_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 291/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_519.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_519_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 292/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_520.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_520_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 293/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_522.csv\n",
      "CSV 文件读取完成，形状为: (165, 52)\n",
      "原始数据长度: 165\n",
      "初始化模型...\n",
      "Meta shape: (165, 2), Full synth shape: (165, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_522_synthetic.csv （shape=(165, 52)）\n",
      "\n",
      "正在处理第 294/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_523.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_523_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 295/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_524.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_524_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 296/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_526.csv\n",
      "CSV 文件读取完成，形状为: (309, 52)\n",
      "原始数据长度: 309\n",
      "初始化模型...\n",
      "Meta shape: (309, 2), Full synth shape: (309, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_526_synthetic.csv （shape=(309, 52)）\n",
      "\n",
      "正在处理第 297/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_527.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_527_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 298/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_528.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_528_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 299/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_529.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_529_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 300/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_530.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_530_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 301/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt634_C_n_532.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "初始化模型...\n",
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt634_C_n_532_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 302/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_535.csv\n",
      "CSV 文件读取完成，形状为: (171, 52)\n",
      "原始数据长度: 171\n",
      "初始化模型...\n",
      "Meta shape: (171, 2), Full synth shape: (171, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_535_synthetic.csv （shape=(171, 52)）\n",
      "\n",
      "正在处理第 303/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_537.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_537_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 304/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_538.csv\n",
      "CSV 文件读取完成，形状为: (443, 52)\n",
      "原始数据长度: 443\n",
      "初始化模型...\n",
      "Meta shape: (443, 2), Full synth shape: (443, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_538_synthetic.csv （shape=(443, 52)）\n",
      "\n",
      "正在处理第 305/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_539.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_539_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 306/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_540.csv\n",
      "CSV 文件读取完成，形状为: (446, 52)\n",
      "原始数据长度: 446\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (446, 2), Full synth shape: (446, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_540_synthetic.csv （shape=(446, 52)）\n",
      "\n",
      "正在处理第 307/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_541.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_541_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 308/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_542.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_542_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 309/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_544.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_544_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 310/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_545.csv\n",
      "CSV 文件读取完成，形状为: (82, 52)\n",
      "原始数据长度: 82\n",
      "初始化模型...\n",
      "Meta shape: (82, 2), Full synth shape: (82, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_545_synthetic.csv （shape=(82, 52)）\n",
      "\n",
      "正在处理第 311/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_546.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_546_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 312/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_548.csv\n",
      "CSV 文件读取完成，形状为: (460, 52)\n",
      "原始数据长度: 460\n",
      "初始化模型...\n",
      "Meta shape: (460, 2), Full synth shape: (460, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_548_synthetic.csv （shape=(460, 52)）\n",
      "\n",
      "正在处理第 313/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_549.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_549_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 314/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_556.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_556_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 315/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_558.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_558_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 316/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_559.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_559_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 317/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_560.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_560_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 318/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_562.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_562_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 319/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_563.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_563_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 320/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_564.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_564_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 321/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_565.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_565_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 322/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_570.csv\n",
      "CSV 文件读取完成，形状为: (299, 52)\n",
      "原始数据长度: 299\n",
      "初始化模型...\n",
      "Meta shape: (299, 2), Full synth shape: (299, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_570_synthetic.csv （shape=(299, 52)）\n",
      "\n",
      "正在处理第 323/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_579.csv\n",
      "CSV 文件读取完成，形状为: (298, 52)\n",
      "原始数据长度: 298\n",
      "初始化模型...\n",
      "Meta shape: (298, 2), Full synth shape: (298, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_579_synthetic.csv （shape=(298, 52)）\n",
      "\n",
      "正在处理第 324/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_581.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_581_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 325/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_586.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_586_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 326/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_590.csv\n",
      "CSV 文件读取完成，形状为: (432, 52)\n",
      "原始数据长度: 432\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (432, 2), Full synth shape: (432, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_590_synthetic.csv （shape=(432, 52)）\n",
      "\n",
      "正在处理第 327/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt744_PD_n_591.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt744_PD_n_591_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 328/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_594.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_594_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 329/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_595.csv\n",
      "CSV 文件读取完成，形状为: (402, 52)\n",
      "原始数据长度: 402\n",
      "初始化模型...\n",
      "Meta shape: (402, 2), Full synth shape: (402, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_595_synthetic.csv （shape=(402, 52)）\n",
      "\n",
      "正在处理第 330/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_597.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_597_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 331/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_598.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_598_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 332/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_600.csv\n",
      "CSV 文件读取完成，形状为: (180, 52)\n",
      "原始数据长度: 180\n",
      "初始化模型...\n",
      "Meta shape: (180, 2), Full synth shape: (180, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_600_synthetic.csv （shape=(180, 52)）\n",
      "\n",
      "正在处理第 333/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_605.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_605_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 334/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_606.csv\n",
      "CSV 文件读取完成，形状为: (170, 52)\n",
      "原始数据长度: 170\n",
      "初始化模型...\n",
      "Meta shape: (170, 2), Full synth shape: (170, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_606_synthetic.csv （shape=(170, 52)）\n",
      "\n",
      "正在处理第 335/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_607.csv\n",
      "CSV 文件读取完成，形状为: (276, 52)\n",
      "原始数据长度: 276\n",
      "初始化模型...\n",
      "Meta shape: (276, 2), Full synth shape: (276, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_607_synthetic.csv （shape=(276, 52)）\n",
      "\n",
      "正在处理第 336/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_616.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_616_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 337/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_617.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_617_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 338/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_618.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_618_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 339/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_619.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_619_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 340/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_622.csv\n",
      "CSV 文件读取完成，形状为: (224, 52)\n",
      "原始数据长度: 224\n",
      "初始化模型...\n",
      "Meta shape: (224, 2), Full synth shape: (224, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_622_synthetic.csv （shape=(224, 52)）\n",
      "\n",
      "正在处理第 341/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_624.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_624_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 342/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_625.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_625_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 343/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_626.csv\n",
      "CSV 文件读取完成，形状为: (312, 52)\n",
      "原始数据长度: 312\n",
      "初始化模型...\n",
      "Meta shape: (312, 2), Full synth shape: (312, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_626_synthetic.csv （shape=(312, 52)）\n",
      "\n",
      "正在处理第 344/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_627.csv\n",
      "CSV 文件读取完成，形状为: (306, 52)\n",
      "原始数据长度: 306\n",
      "初始化模型...\n",
      "Meta shape: (306, 2), Full synth shape: (306, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_627_synthetic.csv （shape=(306, 52)）\n",
      "\n",
      "正在处理第 345/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_628.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_628_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 346/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt784_C_n_629.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt784_C_n_629_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 347/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_329.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_329_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 348/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_330.csv\n",
      "CSV 文件读取完成，形状为: (152, 52)\n",
      "原始数据长度: 152\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (152, 2), Full synth shape: (152, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_330_synthetic.csv （shape=(152, 52)）\n",
      "\n",
      "正在处理第 349/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_331.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_331_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 350/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_332.csv\n",
      "CSV 文件读取完成，形状为: (412, 52)\n",
      "原始数据长度: 412\n",
      "初始化模型...\n",
      "Meta shape: (412, 2), Full synth shape: (412, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_332_synthetic.csv （shape=(412, 52)）\n",
      "\n",
      "正在处理第 351/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_333.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_333_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 352/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_334.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_334_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 353/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_335.csv\n",
      "CSV 文件读取完成，形状为: (378, 52)\n",
      "原始数据长度: 378\n",
      "初始化模型...\n",
      "Meta shape: (378, 2), Full synth shape: (378, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_335_synthetic.csv （shape=(378, 52)）\n",
      "\n",
      "正在处理第 354/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_336.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_336_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 355/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_337.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_337_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 356/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_341.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_341_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 357/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_342.csv\n",
      "CSV 文件读取完成，形状为: (288, 52)\n",
      "原始数据长度: 288\n",
      "初始化模型...\n",
      "Meta shape: (288, 2), Full synth shape: (288, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_342_synthetic.csv （shape=(288, 52)）\n",
      "\n",
      "正在处理第 358/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_343.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_343_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 359/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_346.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_346_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 360/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_349.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_349_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 361/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_351.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_351_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 362/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_355.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_355_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 363/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_357.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_357_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 364/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_358.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_358_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 365/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_359.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_359_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 366/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_360.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_360_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 367/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_362.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_362_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 368/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_363.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_363_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 369/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_364.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_364_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 370/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_365.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_365_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 371/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_366.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_366_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 372/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_367.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_367_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 373/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_368.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_368_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 374/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt842_PD_n_369.csv\n",
      "CSV 文件读取完成，形状为: (469, 52)\n",
      "原始数据长度: 469\n",
      "初始化模型...\n",
      "Meta shape: (469, 2), Full synth shape: (469, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt842_PD_n_369_synthetic.csv （shape=(469, 52)）\n",
      "\n",
      "正在处理第 375/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_210.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_210_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 376/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_212.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_212_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 377/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_213.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_213_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 378/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_217.csv\n",
      "CSV 文件读取完成，形状为: (410, 52)\n",
      "原始数据长度: 410\n",
      "初始化模型...\n",
      "Meta shape: (410, 2), Full synth shape: (410, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_217_synthetic.csv （shape=(410, 52)）\n",
      "\n",
      "正在处理第 379/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_218.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_218_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 380/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_219.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_219_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 381/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_220.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_220_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 382/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_221.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_221_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 383/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_224.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_224_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 384/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_226.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_226_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 385/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_227.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_227_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 386/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_228.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_228_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 387/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_229.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_229_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 388/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_230.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_230_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 389/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt884_C_n_231.csv\n",
      "CSV 文件读取完成，形状为: (246, 52)\n",
      "原始数据长度: 246\n",
      "初始化模型...\n",
      "Meta shape: (246, 2), Full synth shape: (246, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt884_C_n_231_synthetic.csv （shape=(246, 52)）\n",
      "\n",
      "正在处理第 390/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_783.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_783_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 391/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_785.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_785_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 392/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_786.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_786_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 393/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_794.csv\n",
      "CSV 文件读取完成，形状为: (81, 52)\n",
      "原始数据长度: 81\n",
      "初始化模型...\n",
      "Meta shape: (81, 2), Full synth shape: (81, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_794_synthetic.csv （shape=(81, 52)）\n",
      "\n",
      "正在处理第 394/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_795.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_795_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 395/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_796.csv\n",
      "CSV 文件读取完成，形状为: (237, 52)\n",
      "原始数据长度: 237\n",
      "初始化模型...\n",
      "Meta shape: (237, 2), Full synth shape: (237, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_796_synthetic.csv （shape=(237, 52)）\n",
      "\n",
      "正在处理第 396/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_797.csv\n",
      "CSV 文件读取完成，形状为: (188, 52)\n",
      "原始数据长度: 188\n",
      "初始化模型...\n",
      "Meta shape: (188, 2), Full synth shape: (188, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_797_synthetic.csv （shape=(188, 52)）\n",
      "\n",
      "正在处理第 397/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_802.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_802_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 398/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_811.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_811_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 399/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_812.csv\n",
      "CSV 文件读取完成，形状为: (254, 52)\n",
      "原始数据长度: 254\n",
      "初始化模型...\n",
      "Meta shape: (254, 2), Full synth shape: (254, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_812_synthetic.csv （shape=(254, 52)）\n",
      "\n",
      "正在处理第 400/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_813.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_813_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 401/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_814.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_814_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 402/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_815.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_815_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 403/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_816.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_816_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "正在处理第 404/404 个文件...\n",
      "正在处理文件: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\\Pt971_C_n_817.csv\n",
      "CSV 文件读取完成，形状为: (508, 52)\n",
      "原始数据长度: 508\n",
      "初始化模型...\n",
      "Meta shape: (508, 2), Full synth shape: (508, 50)\n",
      "✔ 合成结果已保存：E:/学习工作/PD/pks/SitToStand/Data/Transformer_generate\\Pt971_C_n_817_synthetic.csv （shape=(508, 52)）\n",
      "\n",
      "处理完成！成功处理 404/404 个文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "e:\\python3.10.9\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# generate_single_sts.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "INPUT_DIR = r'E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened'\n",
    "\n",
    "INPUT_FILE_PATTERN = r'E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened/**/*.csv'\n",
    "\n",
    "\n",
    "SEQ_LEN   = 50\n",
    "NUM_KPT   = 25\n",
    "INPUT_DIM = NUM_KPT * 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ------------ Positional Encoding ------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "# ------------ Transformer VAE ------------\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, d_model=128, nhead=4, num_layers=2, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.pos_enc      = PositionalEncoding(d_model, max_len=seq_len)\n",
    "        encoder_layer     = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.encoder      = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc_mu        = nn.Linear(d_model*seq_len, latent_dim)\n",
    "        self.fc_logvar    = nn.Linear(d_model*seq_len, latent_dim)\n",
    "        self.fc_latent    = nn.Linear(latent_dim, d_model*seq_len)\n",
    "        decoder_layer     = nn.TransformerDecoderLayer(d_model, nhead)\n",
    "        self.decoder      = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.output_linear= nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B, L, D)\n",
    "        h = self.input_linear(x)\n",
    "        h = self.pos_enc(h)\n",
    "        out = self.encoder(h.transpose(0,1)).transpose(0,1)\n",
    "        flat = out.contiguous().view(out.size(0), -1)\n",
    "        return self.fc_mu(flat), self.fc_logvar(flat)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        # z: (B, latent_dim)\n",
    "        x = self.fc_latent(z).view(z.size(0), self.seq_len, -1)\n",
    "        tgt = self.pos_enc(x)\n",
    "        memory = torch.zeros(self.seq_len, z.size(0), tgt.size(2), device=z.device)\n",
    "        out = self.decoder(tgt.transpose(0,1), memory).transpose(0,1)\n",
    "        return self.output_linear(out)\n",
    "\n",
    "\n",
    "def process_single_file(input_file_path, output_dir):\n",
    "    \"\"\"处理单个CSV文件并生成合成数据\"\"\"\n",
    "    try:\n",
    "        print(f\"正在处理文件: {input_file_path}\")\n",
    "        \n",
    "        df = pd.read_csv(input_file_path, header=2, engine='python', on_bad_lines='skip')\n",
    "        print(f\"CSV 文件读取完成，形状为: {df.shape}\")\n",
    "\n",
    "        if df.shape[1] < 2 + INPUT_DIM:\n",
    "            print(f\"警告: 文件 {input_file_path} 的列数不足，跳过处理\")\n",
    "            return False\n",
    "\n",
    "        meta = df.iloc[:, :2].reset_index(drop=True)\n",
    "        data_np = df.iloc[:, 2:2+INPUT_DIM].to_numpy(dtype=np.float32)\n",
    "        orig_len = data_np.shape[0]\n",
    "        print(f\"原始数据长度: {orig_len}\")\n",
    "\n",
    "        if np.isnan(data_np).any():\n",
    "            print(\"检测到NaN值，进行填充...\")\n",
    "            data_np = np.nan_to_num(data_np, nan=0.0)\n",
    "\n",
    "        if orig_len < SEQ_LEN:\n",
    "            pad = np.zeros((SEQ_LEN - orig_len, INPUT_DIM), dtype=np.float32)\n",
    "            data_for_model = np.vstack([data_np, pad])\n",
    "        else:\n",
    "            data_for_model = data_np[:SEQ_LEN]\n",
    "\n",
    "        print(\"初始化模型...\")\n",
    "        model = TransformerVAE(INPUT_DIM, SEQ_LEN).to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(data_for_model[None]).to(DEVICE)\n",
    "            mu, logvar = model.encode(x)\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "            synth = model.decode(z)[0].cpu().numpy()\n",
    "\n",
    "        if orig_len > SEQ_LEN:\n",
    "            pad_back = np.zeros((orig_len - SEQ_LEN, INPUT_DIM), dtype=np.float32)\n",
    "            full_synth = np.vstack([synth, pad_back])\n",
    "        else:\n",
    "            full_synth = synth[:orig_len]\n",
    "\n",
    "        print(f\"Meta shape: {meta.shape}, Full synth shape: {full_synth.shape}\")\n",
    "        \n",
    "        if meta.shape[0] != full_synth.shape[0]:\n",
    "            if meta.shape[0] > full_synth.shape[0]:\n",
    "                pad_back = np.zeros((meta.shape[0] - full_synth.shape[0], INPUT_DIM), dtype=np.float32)\n",
    "                full_synth = np.vstack([full_synth, pad_back])\n",
    "            else:\n",
    "                full_synth = full_synth[:meta.shape[0]]\n",
    "\n",
    "        out_arr = np.hstack([meta.values, full_synth])\n",
    "        out_cols = list(meta.columns) + list(df.columns[2:2+INPUT_DIM])\n",
    "        out_df = pd.DataFrame(out_arr, columns=out_cols)\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        input_filename = os.path.basename(input_file_path)\n",
    "        base_name, ext = os.path.splitext(input_filename)\n",
    "        output_filename = f\"{base_name}_synthetic{ext}\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        out_df.to_csv(output_path, header=False, index=False, float_format='%.6f')\n",
    "        print(f\"✔ 合成结果已保存：{output_path} （shape={out_df.shape}）\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 处理文件 {input_file_path} 时出错: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"开始批量处理CSV文件...\")\n",
    "    \n",
    "    all_input_files = glob.glob(INPUT_FILE_PATTERN, recursive=True)\n",
    "    \n",
    "    if not all_input_files:\n",
    "        print(f\"没有找到匹配模式 '{INPUT_FILE_PATTERN}' 的文件。请检查路径和模式是否正确。\")\n",
    "        \n",
    "        direct_pattern = os.path.join(INPUT_DIR, \"*.csv\")\n",
    "        all_input_files = glob.glob(direct_pattern)\n",
    "        \n",
    "        if not all_input_files:\n",
    "            print(f\"也没有在 '{INPUT_DIR}' 中找到CSV文件。\")\n",
    "            print(\"请检查以下几点：\")\n",
    "            print(\"1. 路径是否正确\")\n",
    "            print(\"2. 文件夹中是否包含CSV文件\")\n",
    "            print(\"3. 是否有足够的文件访问权限\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"在主目录中找到 {len(all_input_files)} 个CSV文件\")\n",
    "    else:\n",
    "        print(f\"找到 {len(all_input_files)} 个匹配文件\")\n",
    "    \n",
    "    success_count = 0\n",
    "    for i, file_path in enumerate(all_input_files):\n",
    "        print(f\"\\n正在处理第 {i+1}/{len(all_input_files)} 个文件...\")\n",
    "        if process_single_file(file_path, OUTPUT_DIR):\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\n处理完成！成功处理 {success_count}/{len(all_input_files)} 个文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b14d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory found: E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Example to check if the input folder is accessible\n",
    "    if os.path.exists(INPUT_DIR):\n",
    "        print(f\"Input directory found: {INPUT_DIR}\")\n",
    "    else:\n",
    "        print(f\"Input directory does not exist: {INPUT_DIR}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"Permission error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6590190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# generate_single_sts.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "INPUT_FILE = r'E:/学习工作/PD/pks/SitToStand/Data/STS_2D_skeletons_coarsened/Pt204_C_n_305.csv'\n",
    "\n",
    "SEQ_LEN   = 50\n",
    "NUM_KPT   = 25\n",
    "INPUT_DIM = NUM_KPT * 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Input File: {INPUT_FILE}\")\n",
    "\n",
    "# ------------ Positional Encoding ------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "# ------------ Transformer VAE ------------\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, d_model=128, nhead=4, num_layers=2, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.pos_enc      = PositionalEncoding(d_model, max_len=seq_len)\n",
    "        encoder_layer     = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.encoder      = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc_mu        = nn.Linear(d_model*seq_len, latent_dim)\n",
    "        self.fc_logvar    = nn.Linear(d_model*seq_len, latent_dim)\n",
    "        self.fc_latent    = nn.Linear(latent_dim, d_model*seq_len)\n",
    "        decoder_layer     = nn.TransformerDecoderLayer(d_model, nhead)\n",
    "        self.decoder      = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.output_linear= nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B, L, D)\n",
    "        h = self.input_linear(x)\n",
    "        h = self.pos_enc(h)\n",
    "        out = self.encoder(h.transpose(0,1)).transpose(0,1)\n",
    "        flat = out.contiguous().view(out.size(0), -1)\n",
    "        return self.fc_mu(flat), self.fc_logvar(flat)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        # z: (B, latent_dim)\n",
    "        x = self.fc_latent(z).view(z.size(0), self.seq_len, -1)\n",
    "        tgt = self.pos_enc(x)\n",
    "        memory = torch.zeros(self.seq_len, z.size(0), tgt.size(2), device=z.device)\n",
    "        out = self.decoder(tgt.transpose(0,1), memory).transpose(0,1)\n",
    "        return self.output_linear(out)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"开始读取 CSV 文件...\")\n",
    "    df = pd.read_csv(INPUT_FILE, header=2, engine='python', on_bad_lines='skip')\n",
    "    print(f\"CSV 文件读取完成，形状为: {df.shape}\")\n",
    "\n",
    "    meta = df.iloc[:, :2].reset_index(drop=True)\n",
    "    data_np = df.iloc[:, 2:2+INPUT_DIM].to_numpy(dtype=np.float32)\n",
    "    orig_len = data_np.shape[0]\n",
    "    print(f\"原始数据长度: {orig_len}\")\n",
    "\n",
    "    if orig_len < SEQ_LEN:\n",
    "        pad = np.zeros((SEQ_LEN - orig_len, INPUT_DIM), dtype=np.float32)\n",
    "        data_for_model = np.vstack([data_np, pad])\n",
    "    else:\n",
    "        data_for_model = data_np[:SEQ_LEN]\n",
    "\n",
    "    print(\"初始化模型...\")\n",
    "    model = TransformerVAE(INPUT_DIM, SEQ_LEN).to(DEVICE)\n",
    "    model.to(DEVICE).eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(data_for_model[None]).to(DEVICE)\n",
    "        mu, logvar = model.encode(x)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        synth = model.decode(z)[0].cpu().numpy()\n",
    "\n",
    "    if orig_len > SEQ_LEN:\n",
    "        pad_back = np.zeros((orig_len - SEQ_LEN, INPUT_DIM), dtype=np.float32)\n",
    "        full_synth = np.vstack([synth, pad_back])\n",
    "    else:\n",
    "        full_synth = synth[:orig_len]\n",
    "\n",
    "    print(f\"Meta shape: {meta.shape}, Full synth shape: {full_synth.shape}\")\n",
    "    if meta.shape[0] != full_synth.shape[0]:\n",
    "        if meta.shape[0] > full_synth.shape[0]:\n",
    "            pad_back = np.zeros((meta.shape[0] - full_synth.shape[0], INPUT_DIM), dtype=np.float32)\n",
    "            full_synth = np.vstack([full_synth, pad_back])\n",
    "        else:\n",
    "            full_synth = full_synth[:meta.shape[0]]\n",
    "\n",
    "    out_arr = np.hstack([meta.values, full_synth])\n",
    "    out_cols = list(meta.columns) + list(df.columns[2:2+INPUT_DIM])\n",
    "    out_df = pd.DataFrame(out_arr, columns=out_cols)\n",
    "\n",
    "    if OUTPUT_DIR is None or OUTPUT_DIR == '':\n",
    "        base, _ = os.path.splitext(INPUT_FILE)\n",
    "        OUTPUT_DIR = f\"{base}_synthetic\"\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    out_df.to_csv(os.path.join(OUTPUT_DIR, \"synthetic.csv\"), header=False, index=False, float_format='%.6f')\n",
    "    print(f\"✔ 合成结果已保存：{OUTPUT_DIR} （shape={out_df.shape}）\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}